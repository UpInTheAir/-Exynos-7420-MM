diff --git a/Documentation/sysctl/fs.txt b/Documentation/sysctl/fs.txt
index 88152f2..302b5ed 100755
--- a/Documentation/sysctl/fs.txt
+++ b/Documentation/sysctl/fs.txt
@@ -32,6 +32,8 @@ Currently, these files are in /proc/sys/fs:
 - nr_open
 - overflowuid
 - overflowgid
+- pipe-user-pages-hard
+- pipe-user-pages-soft
 - protected_hardlinks
 - protected_symlinks
 - suid_dumpable
@@ -159,6 +161,27 @@ The default is 65534.
 
 ==============================================================
 
+pipe-user-pages-hard:
+
+Maximum total number of pages a non-privileged user may allocate for pipes.
+Once this limit is reached, no new pipes may be allocated until usage goes
+below the limit again. When set to 0, no limit is applied, which is the default
+setting.
+
+==============================================================
+
+pipe-user-pages-soft:
+
+Maximum total number of pages a non-privileged user may allocate for pipes
+before the pipe size gets limited to a single page. Once this limit is reached,
+new pipes will be limited to a single page in size for this user in order to
+limit total memory usage, and trying to increase them using fcntl() will be
+denied until usage goes below the limit again. The default value allows to
+allocate up to 1024 pipes at their default size. When set to 0, no limit is
+applied.
+
+==============================================================
+
 protected_hardlinks:
 
 A long-standing class of security issues is the hardlink-based
diff --git a/arch/arm64/boot/dts/exynos7420-noblelte_common_battery_09.dtsi b/arch/arm64/boot/dts/exynos7420-noblelte_common_battery_09.dtsi
index b00c398..1a57d01 100755
--- a/arch/arm64/boot/dts/exynos7420-noblelte_common_battery_09.dtsi
+++ b/arch/arm64/boot/dts/exynos7420-noblelte_common_battery_09.dtsi
@@ -90,6 +90,7 @@
 
 		battery,chg_temp_check = <1>;
 		battery,wpc_temp_check = <1>;
+		battery,mix_temp_check = <1>;
 
 		battery,polling_time = <10 30 30 30 3600>;
 
@@ -239,6 +240,15 @@
 
 		battery,sleep_mode_limit_current = <500>;
 
+		battery,mix_high_tbat = <990>;
+		battery,mix_high_tchg = <990>;
+		battery,mix_high_tbat_recov = <990>;
+		battery,mix_input_limit_current = <100>;
+		battery,mix_high_tbat_hv = <410>;
+		battery,mix_high_tchg_hv = <500>;
+		battery,mix_high_tbat_recov_hv = <380>;
+		battery,mix_input_limit_current_hv = <100>;
+
 		/* SEC_BATTERY_FULL_CONDITION_SOC |
 		   SEC_BATTERY_FULL_CONDITION_NOTIMEFULL |
 		   SEC_BATTERY_FULL_CONDITION_VCELL */
diff --git a/arch/arm64/kernel/perf_event.c b/arch/arm64/kernel/perf_event.c
index dfcd8fa..33676dc 100755
--- a/arch/arm64/kernel/perf_event.c
+++ b/arch/arm64/kernel/perf_event.c
@@ -316,22 +316,31 @@ out:
 }
 
 static int
-validate_event(struct pmu_hw_events *hw_events,
-	       struct perf_event *event)
+validate_event(struct pmu *pmu, struct pmu_hw_events *hw_events,
+				struct perf_event *event)
 {
-	struct arm_pmu *armpmu = to_arm_pmu(event->pmu);
+	struct arm_pmu *armpmu;
 	struct hw_perf_event fake_event = event->hw;
 	struct pmu *leader_pmu = event->group_leader->pmu;
 
 	if (is_software_event(event))
 		return 1;
 
+	/*
+	 * Reject groups spanning multiple HW PMUs (e.g. CPU + CCI). The
+	 * core perf code won't check that the pmu->ctx == leader->ctx
+	 * until after pmu->event_init(event).
+	 */
+	if (event->pmu != pmu)
+		return 0;
+
 	if (event->pmu != leader_pmu || event->state < PERF_EVENT_STATE_OFF)
 		return 1;
 
 	if (event->state == PERF_EVENT_STATE_OFF && !event->attr.enable_on_exec)
 		return 1;
 
+	armpmu = to_arm_pmu(event->pmu);
 	return armpmu->get_event_idx(hw_events, &fake_event) >= 0;
 }
 
@@ -349,15 +358,15 @@ validate_group(struct perf_event *event)
 	memset(fake_used_mask, 0, sizeof(fake_used_mask));
 	fake_pmu.used_mask = fake_used_mask;
 
-	if (!validate_event(&fake_pmu, leader))
+	if (!validate_event(event->pmu, &fake_pmu, leader))
 		return -EINVAL;
 
 	list_for_each_entry(sibling, &leader->sibling_list, group_entry) {
-		if (!validate_event(&fake_pmu, sibling))
+		if (!validate_event(event->pmu, &fake_pmu, sibling))
 			return -EINVAL;
 	}
 
-	if (!validate_event(&fake_pmu, event))
+	if (!validate_event(event->pmu, &fake_pmu, event))
 		return -EINVAL;
 
 	return 0;
diff --git a/drivers/battery/sec_battery.c b/drivers/battery/sec_battery.c
index 2c05574..460444c 100755
--- a/drivers/battery/sec_battery.c
+++ b/drivers/battery/sec_battery.c
@@ -1718,7 +1718,7 @@ static void sec_bat_mix_temperature_check(
 				(battery->temperature >= mix_high_tbat) &&
 				(battery->chg_temp >= mix_high_tchg)) {
 				battery->mix_limit = SEC_BATTERY_MIX_TEMP_HIGH;
-				value.intval = battery->pdata->mix_input_limit_current;
+				value.intval = mix_input_limit_current;
 				psy_do_property(battery->pdata->charger_name, set,
 						POWER_SUPPLY_PROP_CURRENT_MAX, value);
 				dev_info(battery->dev,"%s: Input current is reduced by Temp(tbat:%d, tchg:%d)\n",
diff --git a/drivers/hid/hid-core.c b/drivers/hid/hid-core.c
index 26168b5..67d658b 100755
--- a/drivers/hid/hid-core.c
+++ b/drivers/hid/hid-core.c
@@ -1138,6 +1138,7 @@ static void hid_input_field(struct hid_device *hid, struct hid_field *field,
 		/* Ignore report if ErrorRollOver */
 		if (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&
 		    value[n] >= min && value[n] <= max &&
+		    value[n] - min < field->maxusage &&
 		    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)
 			goto exit;
 	}
@@ -1150,11 +1151,13 @@ static void hid_input_field(struct hid_device *hid, struct hid_field *field,
 		}
 
 		if (field->value[n] >= min && field->value[n] <= max
+			&& field->value[n] - min < field->maxusage
 			&& field->usage[field->value[n] - min].hid
 			&& search(value, field->value[n], count))
 				hid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);
 
 		if (value[n] >= min && value[n] <= max
+			&& value[n] - min < field->maxusage
 			&& field->usage[value[n] - min].hid
 			&& search(field->value, value[n], count))
 				hid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);
diff --git a/drivers/media/media-device.c b/drivers/media/media-device.c
index fdb5840..88c1606 100755
--- a/drivers/media/media-device.c
+++ b/drivers/media/media-device.c
@@ -141,6 +141,8 @@ static long __media_device_enum_links(struct media_device *mdev,
 
 		for (p = 0; p < entity->num_pads; p++) {
 			struct media_pad_desc pad;
+
+			memset(&pad, 0, sizeof(pad));
 			media_device_kpad_to_upad(&entity->pads[p], &pad);
 			if (copy_to_user(&links->pads[p], &pad, sizeof(pad)))
 				return -EFAULT;
@@ -158,6 +160,7 @@ static long __media_device_enum_links(struct media_device *mdev,
 			if (entity->links[l].source->entity != entity)
 				continue;
 
+			memset(&link, 0, sizeof(link));
 			media_device_kpad_to_upad(entity->links[l].source,
 						  &link.source);
 			media_device_kpad_to_upad(entity->links[l].sink,
diff --git a/drivers/media/platform/exynos/fimg2d/fimg2d_drv.c b/drivers/media/platform/exynos/fimg2d/fimg2d_drv.c
index 206fa8e..41fffa9 100755
--- a/drivers/media/platform/exynos/fimg2d/fimg2d_drv.c
+++ b/drivers/media/platform/exynos/fimg2d/fimg2d_drv.c
@@ -393,6 +393,7 @@ static long fimg2d_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 	struct fimg2d_context *ctx;
 	struct mm_struct *mm;
 	struct fimg2d_dma *usr_dst;
+	struct fimg2d_bltcmd *bltcmd;
 
 	ctx = file->private_data;
 
@@ -429,6 +430,9 @@ static long fimg2d_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		usr_dst = kzalloc(sizeof(struct fimg2d_dma), GFP_KERNEL);
 		if (!usr_dst) {
 			fimg2d_err("failed to allocate memory for fimg2d_dma\n");
+			bltcmd = fimg2d_get_first_command(ctrl);
+			if (bltcmd)
+				fimg2d_del_command(ctrl, bltcmd);
 			mutex_unlock(&ctrl->drvlock);
 			mmput(mm);
 			return -ENOMEM;
@@ -437,6 +441,9 @@ static long fimg2d_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		ret = store_user_dst((struct fimg2d_blit __user *)arg, usr_dst);
 		if (ret) {
 			fimg2d_err("store_user_dst() not allowed.\n");
+			bltcmd = fimg2d_get_first_command(ctrl);
+			if (bltcmd)
+				fimg2d_del_command(ctrl, bltcmd);
 			mutex_unlock(&ctrl->drvlock);
 			kfree(usr_dst);
 			mmput(mm);
@@ -492,6 +499,13 @@ static long fimg2d_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 			return -EFAULT;
 
 		mutex_lock(&ctrl->drvlock);
+		if (atomic_read(&ctrl->drvact) == act) {
+			fimg2d_info("Duplicated %s request is ignored\n",
+				act == DRV_ACT ? "DRV_ACT" : "DRV_DEACT");
+			mutex_unlock(&ctrl->drvlock);
+			break;
+		}
+
 		atomic_set(&ctrl->drvact, act);
 		if (act == DRV_ACT) {
 			fimg2d_power_control(ctrl, FIMG2D_PW_OFF);
diff --git a/drivers/sensorhub/atmel/max86900.c b/drivers/sensorhub/atmel/max86900.c
index cb9d05a..024b698 100755
--- a/drivers/sensorhub/atmel/max86900.c
+++ b/drivers/sensorhub/atmel/max86900.c
@@ -901,6 +901,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -908,9 +910,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -1004,15 +1010,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1176,6 +1188,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensorhub/atmel/max86900.h b/drivers/sensorhub/atmel/max86900.h
index 3856624..7e27254 100755
--- a/drivers/sensorhub/atmel/max86900.h
+++ b/drivers/sensorhub/atmel/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 	struct regulator *vdd_3p3;
 	const char *vldo39;
diff --git a/drivers/sensorhub/brcm/adpd142.c b/drivers/sensorhub/brcm/adpd142.c
index 3128194..e25ec17 100755
--- a/drivers/sensorhub/brcm/adpd142.c
+++ b/drivers/sensorhub/brcm/adpd142.c
@@ -240,6 +240,7 @@ to control the adpd142 software part.
 struct adpd142_data {
 	struct i2c_client *client;
 	struct mutex mutex;/*for chip structure*/
+	struct mutex storelock;
 	struct device *dev;
 	struct input_dev *ptr_sample_inputdev;
 	struct adpd_platform_data *ptr_config;
@@ -2218,15 +2219,21 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_test_result != NULL)
 		kfree(pst_adpd->eol_test_result);
 
 	pst_adpd->eol_test_result = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_test_result == NULL) {
 		pr_err("adpd142_%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+	
 	pr_info("adpd142_%s - result = %s, buf_len(%u)\n", __func__, pst_adpd->eol_test_result, buf_len);
 	pst_adpd->eol_test_status = 1;
 
@@ -2271,15 +2278,20 @@ static ssize_t adpd142_eol_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_lib_ver != NULL)
 		kfree(pst_adpd->eol_lib_ver);
 
 	pst_adpd->eol_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
 	pr_info("%s - eol_lib_ver = %s\n", __func__, pst_adpd->eol_lib_ver);
 	return size;
 }
@@ -2307,15 +2319,21 @@ static ssize_t adpd142_elf_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->elf_lib_ver != NULL)
 		kfree(pst_adpd->elf_lib_ver);
 
 	pst_adpd->elf_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->elf_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->elf_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+
 	return size;
 }
 
@@ -2464,6 +2482,7 @@ adpd_i2c_probe(struct i2c_client *client, const struct i2c_device_id *id)
 	}
 
 	mutex_init(&pst_adpd->mutex);
+	mutex_init(&pst_adpd->storelock);
 
 	pst_adpd->skip_i2c_msleep = 1;
 	pst_adpd->client = client;
diff --git a/drivers/sensorhub/brcm/max86900.c b/drivers/sensorhub/brcm/max86900.c
index 08569d9..89165e5 100755
--- a/drivers/sensorhub/brcm/max86900.c
+++ b/drivers/sensorhub/brcm/max86900.c
@@ -889,6 +889,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -896,9 +898,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -992,15 +998,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1157,6 +1169,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensorhub/brcm/max86900.h b/drivers/sensorhub/brcm/max86900.h
index 40f0ae7..a5c89c0 100755
--- a/drivers/sensorhub/brcm/max86900.h
+++ b/drivers/sensorhub/brcm/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 	struct regulator *vdd_3p3;
 	bool *bio_status;
diff --git a/drivers/sensorhub/brcm_legacy/adpd142.c b/drivers/sensorhub/brcm_legacy/adpd142.c
index fde9029..d5234c9 100755
--- a/drivers/sensorhub/brcm_legacy/adpd142.c
+++ b/drivers/sensorhub/brcm_legacy/adpd142.c
@@ -240,6 +240,7 @@ to control the adpd142 software part.
 struct adpd142_data {
 	struct i2c_client *client;
 	struct mutex mutex;/*for chip structure*/
+	struct mutex storelock;
 	struct device *dev;
 	struct input_dev *ptr_sample_inputdev;
 	struct adpd_platform_data *ptr_config;
@@ -2217,15 +2218,21 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_test_result != NULL)
 		kfree(pst_adpd->eol_test_result);
 
 	pst_adpd->eol_test_result = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_test_result == NULL) {
 		pr_err("adpd142_%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+	
 	pr_info("adpd142_%s - result = %s, buf_len(%u)\n", __func__, pst_adpd->eol_test_result, buf_len);
 	pst_adpd->eol_test_status = 1;
 
@@ -2270,15 +2277,20 @@ static ssize_t adpd142_eol_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_lib_ver != NULL)
 		kfree(pst_adpd->eol_lib_ver);
 
 	pst_adpd->eol_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
 	pr_info("%s - eol_lib_ver = %s\n", __func__, pst_adpd->eol_lib_ver);
 	return size;
 }
@@ -2306,15 +2318,21 @@ static ssize_t adpd142_elf_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->elf_lib_ver != NULL)
 		kfree(pst_adpd->elf_lib_ver);
 
 	pst_adpd->elf_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->elf_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->elf_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+
 	return size;
 }
 
@@ -2430,6 +2448,7 @@ adpd_i2c_probe(struct i2c_client *client, const struct i2c_device_id *id)
 	}
 
 	mutex_init(&pst_adpd->mutex);
+	mutex_init(&pst_adpd->storelock);
 
 	pst_adpd->skip_i2c_msleep = 1;
 	pst_adpd->client = client;
diff --git a/drivers/sensorhub/brcm_legacy/max86900.c b/drivers/sensorhub/brcm_legacy/max86900.c
index 08569d9..89165e5 100755
--- a/drivers/sensorhub/brcm_legacy/max86900.c
+++ b/drivers/sensorhub/brcm_legacy/max86900.c
@@ -889,6 +889,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -896,9 +898,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -992,15 +998,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1157,6 +1169,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensorhub/brcm_legacy/max86900.h b/drivers/sensorhub/brcm_legacy/max86900.h
index 40f0ae7..a5c89c0 100755
--- a/drivers/sensorhub/brcm_legacy/max86900.h
+++ b/drivers/sensorhub/brcm_legacy/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 	struct regulator *vdd_3p3;
 	bool *bio_status;
diff --git a/drivers/sensorhub/stm/adpd142.c b/drivers/sensorhub/stm/adpd142.c
index 5267987..17ccc3a 100755
--- a/drivers/sensorhub/stm/adpd142.c
+++ b/drivers/sensorhub/stm/adpd142.c
@@ -240,6 +240,7 @@ to control the adpd142 software part.
 struct adpd142_data {
 	struct i2c_client *client;
 	struct mutex mutex;/*for chip structure*/
+	struct mutex storelock;
 	struct device *dev;
 	struct input_dev *ptr_sample_inputdev;
 	struct adpd_platform_data *ptr_config;
@@ -2223,15 +2224,21 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_test_result != NULL)
 		kfree(pst_adpd->eol_test_result);
 
 	pst_adpd->eol_test_result = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_test_result == NULL) {
 		pr_err("adpd142_%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+	
 	pr_info("adpd142_%s - result = %s, buf_len(%u)\n", __func__, pst_adpd->eol_test_result, buf_len);
 	pst_adpd->eol_test_status = 1;
 
@@ -2276,15 +2283,20 @@ static ssize_t adpd142_eol_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->eol_lib_ver != NULL)
 		kfree(pst_adpd->eol_lib_ver);
 
 	pst_adpd->eol_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->eol_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->eol_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
 	pr_info("%s - eol_lib_ver = %s\n", __func__, pst_adpd->eol_lib_ver);
 	return size;
 }
@@ -2312,15 +2324,21 @@ static ssize_t adpd142_elf_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&pst_adpd->storelock);
+
 	if (pst_adpd->elf_lib_ver != NULL)
 		kfree(pst_adpd->elf_lib_ver);
 
 	pst_adpd->elf_lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (pst_adpd->elf_lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&pst_adpd->storelock);
 		return -ENOMEM;
 	}
 	strncpy(pst_adpd->elf_lib_ver, buf, buf_len);
+
+	mutex_unlock(&pst_adpd->storelock);
+
 	return size;
 }
 
@@ -2487,6 +2505,7 @@ adpd_i2c_probe(struct i2c_client *client, const struct i2c_device_id *id)
 	}
 
 	mutex_init(&pst_adpd->mutex);
+	mutex_init(&pst_adpd->storelock);
 
 	pst_adpd->skip_i2c_msleep = 1;
 	pst_adpd->client = client;
diff --git a/drivers/sensorhub/stm/max86900.c b/drivers/sensorhub/stm/max86900.c
index e80d335..83a1a9d 100755
--- a/drivers/sensorhub/stm/max86900.c
+++ b/drivers/sensorhub/stm/max86900.c
@@ -897,6 +897,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -904,9 +906,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -1000,15 +1006,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1207,6 +1219,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensorhub/stm/max86900.h b/drivers/sensorhub/stm/max86900.h
index 820f6cd..85f8144 100755
--- a/drivers/sensorhub/stm/max86900.h
+++ b/drivers/sensorhub/stm/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 #if defined(CONFIG_SEC_KACTIVE_PROJECT) || defined(CONFIG_MACH_KSPORTSLTE_SPR)
 	struct regulator *vdd_3p3;
diff --git a/drivers/sensorhub/stm_legacy/max86900.c b/drivers/sensorhub/stm_legacy/max86900.c
index e80d335..83a1a9d 100755
--- a/drivers/sensorhub/stm_legacy/max86900.c
+++ b/drivers/sensorhub/stm_legacy/max86900.c
@@ -897,6 +897,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -904,9 +906,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -1000,15 +1006,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1207,6 +1219,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensorhub/stm_legacy/max86900.h b/drivers/sensorhub/stm_legacy/max86900.h
index 820f6cd..85f8144 100755
--- a/drivers/sensorhub/stm_legacy/max86900.h
+++ b/drivers/sensorhub/stm_legacy/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 #if defined(CONFIG_SEC_KACTIVE_PROJECT) || defined(CONFIG_MACH_KSPORTSLTE_SPR)
 	struct regulator *vdd_3p3;
diff --git a/drivers/sensors/max86900.c b/drivers/sensors/max86900.c
index 842f0c8..f48f2b4 100755
--- a/drivers/sensors/max86900.c
+++ b/drivers/sensors/max86900.c
@@ -895,6 +895,8 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (buf_len > MAX_EOL_RESULT)
 		buf_len = MAX_EOL_RESULT;
 
+	mutex_lock(&data->storelock);
+
 	if (data->eol_test_result != NULL)
 		kfree(data->eol_test_result);
 
@@ -902,9 +904,13 @@ static ssize_t eol_test_result_store(struct device *dev,
 	if (data->eol_test_result == NULL) {
 		pr_err("max86900_%s - couldn't allocate memory\n",
 			__func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->eol_test_result, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+	
 	pr_info("max86900_%s - result = %s, buf_len(%u)\n", __func__, data->eol_test_result, buf_len);
 	data->eol_test_status = 1;
 	return size;
@@ -998,15 +1004,21 @@ static ssize_t max86900_lib_ver_store(struct device *dev,
 	if (buf_len > MAX_LIB_VER)
 		buf_len = MAX_LIB_VER;
 
+	mutex_lock(&data->storelock);
+
 	if (data->lib_ver != NULL)
 		kfree(data->lib_ver);
 
 	data->lib_ver = kzalloc(sizeof(char) * buf_len, GFP_KERNEL);
 	if (data->lib_ver == NULL) {
 		pr_err("%s - couldn't allocate memory\n", __func__);
+		mutex_unlock(&data->storelock);
 		return -ENOMEM;
 	}
 	strncpy(data->lib_ver, buf, buf_len);
+
+	mutex_unlock(&data->storelock);
+
 	pr_info("%s - lib_ver = %s\n", __func__, data->lib_ver);
 	return size;
 }
@@ -1163,6 +1175,7 @@ int max86900_probe(struct i2c_client *client, const struct i2c_device_id *id )
 
 	mutex_init(&data->i2clock);
 	mutex_init(&data->activelock);
+	mutex_init(&data->storelock);
 
 	data->dev = &client->dev;
 
diff --git a/drivers/sensors/max86900.h b/drivers/sensors/max86900.h
index b1d50ff..14ed359 100755
--- a/drivers/sensors/max86900.h
+++ b/drivers/sensors/max86900.h
@@ -80,6 +80,7 @@ struct max86900_device_data
 	struct input_dev *hrm_input_dev;
 	struct mutex i2clock;
 	struct mutex activelock;
+	struct mutex storelock;
 	struct regulator *vdd_1p8;
 	struct regulator *vdd_3p3;
 	bool *bio_status;
diff --git a/drivers/staging/android/binder.c b/drivers/staging/android/binder.c
index 59bd3b3..287d16c 100755
--- a/drivers/staging/android/binder.c
+++ b/drivers/staging/android/binder.c
@@ -994,7 +994,7 @@ static int binder_dec_node(struct binder_node *node, int strong, int internal)
 
 
 static struct binder_ref *binder_get_ref(struct binder_proc *proc,
-					 uint32_t desc)
+					 uint32_t desc, bool need_strong_ref)
 {
 	struct rb_node *n = proc->refs_by_desc.rb_node;
 	struct binder_ref *ref;
@@ -1002,12 +1002,16 @@ static struct binder_ref *binder_get_ref(struct binder_proc *proc,
 	while (n) {
 		ref = rb_entry(n, struct binder_ref, rb_node_desc);
 
-		if (desc < ref->desc)
+		if (desc < ref->desc) {
 			n = n->rb_left;
-		else if (desc > ref->desc)
+		} else if (desc > ref->desc) {
 			n = n->rb_right;
-		else
+		} else if (need_strong_ref && !ref->strong) {
+			binder_user_error("tried to use weak ref as strong ref\n");
+			return NULL;
+		} else {
 			return ref;
+		}
 	}
 	return NULL;
 }
@@ -1271,7 +1275,8 @@ static void binder_transaction_buffer_release(struct binder_proc *proc,
 		} break;
 		case BINDER_TYPE_HANDLE:
 		case BINDER_TYPE_WEAK_HANDLE: {
-			struct binder_ref *ref = binder_get_ref(proc, fp->handle);
+			struct binder_ref *ref = binder_get_ref(proc, fp->handle,
+						fp->type == BINDER_TYPE_HANDLE);
 			if (ref == NULL) {
 				pr_err("transaction release %d bad handle %d\n",
 				 debug_id, fp->handle);
@@ -1364,7 +1369,7 @@ static void binder_transaction(struct binder_proc *proc,
 	} else {
 		if (tr->target.handle) {
 			struct binder_ref *ref;
-			ref = binder_get_ref(proc, tr->target.handle);
+			ref = binder_get_ref(proc, tr->target.handle, true);
 			if (ref == NULL) {
 				binder_user_error("%d:%d got transaction to invalid handle\n",
 					proc->pid, thread->pid);
@@ -1555,7 +1560,9 @@ static void binder_transaction(struct binder_proc *proc,
 				fp->type = BINDER_TYPE_HANDLE;
 			else
 				fp->type = BINDER_TYPE_WEAK_HANDLE;
+			fp->binder = 0;
 			fp->handle = ref->desc;
+			fp->cookie = 0;
 			binder_inc_ref(ref, fp->type == BINDER_TYPE_HANDLE,
 				       &thread->todo);
 
@@ -1567,7 +1574,8 @@ static void binder_transaction(struct binder_proc *proc,
 		} break;
 		case BINDER_TYPE_HANDLE:
 		case BINDER_TYPE_WEAK_HANDLE: {
-			struct binder_ref *ref = binder_get_ref(proc, fp->handle);
+			struct binder_ref *ref = binder_get_ref(proc, fp->handle,
+						fp->type == BINDER_TYPE_HANDLE);
 			if (ref == NULL) {
 				binder_user_error("%d:%d got transaction with invalid handle, %d\n",
 						proc->pid,
@@ -1599,7 +1607,9 @@ static void binder_transaction(struct binder_proc *proc,
 					return_error = BR_FAILED_REPLY;
 					goto err_binder_get_ref_for_node_failed;
 				}
+				fp->binder = 0;
 				fp->handle = new_ref->desc;
+				fp->cookie = 0;
 				binder_inc_ref(new_ref, fp->type == BINDER_TYPE_HANDLE, NULL);
 				trace_binder_transaction_ref_to_ref(t, ref,
 								    new_ref);
@@ -1651,6 +1661,7 @@ static void binder_transaction(struct binder_proc *proc,
 			binder_debug(BINDER_DEBUG_TRANSACTION,
 				     "        fd %d -> %d\n", fp->handle, target_fd);
 			/* TODO: fput? */
+			fp->binder = 0;
 			fp->handle = target_fd;
 		} break;
 
@@ -1771,7 +1782,9 @@ int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread,
 						ref->desc);
 				}
 			} else
-				ref = binder_get_ref(proc, target);
+				ref = binder_get_ref(proc, target,
+						     cmd == BC_ACQUIRE ||
+						     cmd == BC_RELEASE);
 			if (ref == NULL) {
 				binder_user_error("%d:%d refcount change on invalid ref %d\n",
 					proc->pid, thread->pid, target);
@@ -1974,7 +1987,7 @@ int binder_thread_write(struct binder_proc *proc, struct binder_thread *thread,
 			if (get_user(cookie, (binder_uintptr_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(binder_uintptr_t);
-			ref = binder_get_ref(proc, target);
+			ref = binder_get_ref(proc, target, false);
 			if (ref == NULL) {
 				binder_user_error("%d:%d %s invalid ref %d\n",
 					proc->pid, thread->pid,
@@ -3263,7 +3276,7 @@ static void print_binder_node(struct seq_file *m, struct binder_node *node)
 
 static void print_binder_ref(struct seq_file *m, struct binder_ref *ref)
 {
-	seq_printf(m, "  ref %d: desc %d %snode %d s %d w %d d %p\n",
+	seq_printf(m, "  ref %d: desc %d %snode %d s %d w %d d %pK\n",
 		   ref->debug_id, ref->desc, ref->node->proc ? "" : "dead ",
 		   ref->node->debug_id, ref->strong, ref->weak, ref->death);
 }
diff --git a/drivers/staging/android/ion/ion_heap.c b/drivers/staging/android/ion/ion_heap.c
index a0fe05d..7604235 100755
--- a/drivers/staging/android/ion/ion_heap.c
+++ b/drivers/staging/android/ion/ion_heap.c
@@ -338,8 +338,9 @@ struct ion_heap *ion_heap_create(struct ion_platform_heap *heap_data)
 
 	switch (heap_data->type) {
 	case ION_HEAP_TYPE_SYSTEM_CONTIG:
-		heap = ion_system_contig_heap_create(heap_data);
-		break;
+		pr_err("%s: Heap type is disabled: %d\n", __func__,
+			heap_data->type);
+		return ERR_PTR(-EINVAL);
 	case ION_HEAP_TYPE_SYSTEM:
 		heap = ion_system_heap_create(heap_data);
 		break;
@@ -377,7 +378,8 @@ void ion_heap_destroy(struct ion_heap *heap)
 
 	switch (heap->type) {
 	case ION_HEAP_TYPE_SYSTEM_CONTIG:
-		ion_system_contig_heap_destroy(heap);
+		pr_err("%s: Heap type is disabled: %d\n", __func__,
+			heap->type);
 		break;
 	case ION_HEAP_TYPE_SYSTEM:
 		ion_system_heap_destroy(heap);
diff --git a/drivers/staging/android/sync.c b/drivers/staging/android/sync.c
index c65cd1f..8d9adaa 100755
--- a/drivers/staging/android/sync.c
+++ b/drivers/staging/android/sync.c
@@ -612,14 +612,14 @@ int sync_fence_wait(struct sync_fence *fence, long timeout)
 		return err;
 
 	if (fence->status < 0) {
-		pr_info("fence error %d on [%p]\n", fence->status, fence);
+		pr_info("fence error %d on [%pK]\n", fence->status, fence);
 		sync_dump();
 		return fence->status;
 	}
 
 	if (fence->status == 0) {
 		if (timeout > 0) {
-			pr_info("fence timeout on [%p] after %dms\n", fence,
+			pr_info("fence timeout on [%pK] after %dms\n", fence,
 				jiffies_to_msecs(timeout));
 			sync_dump();
 		}
@@ -915,7 +915,7 @@ static void sync_print_fence(struct seq_file *s, struct sync_fence *fence)
 	struct list_head *pos;
 	unsigned long flags;
 
-	seq_printf(s, "[%p] %s: %s\n", fence, fence->name,
+	seq_printf(s, "[%pK] %s: %s\n", fence, fence->name,
 		   sync_status_str(fence->status));
 
 	list_for_each(pos, &fence->pt_list_head) {
diff --git a/drivers/tty/tty_ldisc.c b/drivers/tty/tty_ldisc.c
index b7b8048..420dd6e 100755
--- a/drivers/tty/tty_ldisc.c
+++ b/drivers/tty/tty_ldisc.c
@@ -415,6 +415,10 @@ EXPORT_SYMBOL_GPL(tty_ldisc_flush);
  *	they are not on hot paths so a little discipline won't do
  *	any harm.
  *
+ *	The line discipline-related tty_struct fields are reset to
+ *	prevent the ldisc driver from re-using stale information for
+ *	the new ldisc instance.
+ *
  *	Locking: takes termios_mutex
  */
 
@@ -423,6 +427,9 @@ static void tty_set_termios_ldisc(struct tty_struct *tty, int num)
 	mutex_lock(&tty->termios_mutex);
 	tty->termios.c_line = num;
 	mutex_unlock(&tty->termios_mutex);
+
+	tty->disc_data = NULL;
+	tty->receive_room = 0;
 }
 
 /**
diff --git a/drivers/tty/tty_ldsem.c b/drivers/tty/tty_ldsem.c
index 22fad8a..d8a55e8 100755
--- a/drivers/tty/tty_ldsem.c
+++ b/drivers/tty/tty_ldsem.c
@@ -86,11 +86,21 @@ static inline long ldsem_atomic_update(long delta, struct ld_semaphore *sem)
 	return atomic_long_add_return(delta, (atomic_long_t *)&sem->count);
 }
 
+/*
+ * ldsem_cmpxchg() updates @*old with the last-known sem->count value.
+ * Returns 1 if count was successfully changed; @*old will have @new value.
+ * Returns 0 if count was not changed; @*old will have most recent sem->count
+ */
 static inline int ldsem_cmpxchg(long *old, long new, struct ld_semaphore *sem)
 {
-	long tmp = *old;
-	*old = atomic_long_cmpxchg(&sem->count, *old, new);
-	return *old == tmp;
+	long tmp = atomic_long_cmpxchg(&sem->count, *old, new);
+	if (tmp == *old) {
+		*old = new;
+		return 1;
+	} else {
+		*old = tmp;
+		return 0;
+	}
 }
 
 /*
diff --git a/drivers/usb/core/devio.c b/drivers/usb/core/devio.c
index b4f2617..731360e 100755
--- a/drivers/usb/core/devio.c
+++ b/drivers/usb/core/devio.c
@@ -1105,10 +1105,11 @@ static int proc_getdriver(struct dev_state *ps, void __user *arg)
 
 static int proc_connectinfo(struct dev_state *ps, void __user *arg)
 {
-	struct usbdevfs_connectinfo ci = {
-		.devnum = ps->dev->devnum,
-		.slow = ps->dev->speed == USB_SPEED_LOW
-	};
+	struct usbdevfs_connectinfo ci;
+
+	memset(&ci, 0, sizeof(ci));
+	ci.devnum = ps->dev->devnum;
+	ci.slow = ps->dev->speed == USB_SPEED_LOW;
 
 	if (copy_to_user(arg, &ci, sizeof(ci)))
 		return -EFAULT;
diff --git a/drivers/usb/core/hub.c b/drivers/usb/core/hub.c
index 9876ef9..3dd4238 100755
--- a/drivers/usb/core/hub.c
+++ b/drivers/usb/core/hub.c
@@ -1022,6 +1022,7 @@ enum hub_activation_type {
 
 static void hub_init_func2(struct work_struct *ws);
 static void hub_init_func3(struct work_struct *ws);
+static void hub_release(struct kref *kref);
 
 static void hub_activate(struct usb_hub *hub, enum hub_activation_type type)
 {
@@ -1034,11 +1035,20 @@ static void hub_activate(struct usb_hub *hub, enum hub_activation_type type)
 	unsigned delay;
 
 	/* Continue a partial initialization */
-	if (type == HUB_INIT2)
-		goto init2;
-	if (type == HUB_INIT3)
-		goto init3;
+	if (type == HUB_INIT2 || type == HUB_INIT3) {
+		device_lock(hub->intfdev);
 
+		/* Was the hub disconnected while we were waiting? */
+		if (hub->disconnected) {
+			device_unlock(hub->intfdev);
+			kref_put(&hub->kref, hub_release);
+			return;
+		}
+		if (type == HUB_INIT2)
+			goto init2;
+		goto init3;
+	}
+	kref_get(&hub->kref);
 	/* The superspeed hub except for root hub has to use Hub Depth
 	 * value as an offset into the route string to locate the bits
 	 * it uses to determine the downstream port number. So hub driver
@@ -1238,6 +1248,7 @@ static void hub_activate(struct usb_hub *hub, enum hub_activation_type type)
 			PREPARE_DELAYED_WORK(&hub->init_work, hub_init_func3);
 			schedule_delayed_work(&hub->init_work,
 					msecs_to_jiffies(delay));
+			device_unlock(hub->intfdev);
 			return;		/* Continues at init3: below */
 		} else {
 			msleep(delay);
@@ -1258,6 +1269,11 @@ static void hub_activate(struct usb_hub *hub, enum hub_activation_type type)
 	/* Allow autosuspend if it was suppressed */
 	if (type <= HUB_INIT3)
 		usb_autopm_put_interface_async(to_usb_interface(hub->intfdev));
+
+	if (type == HUB_INIT2 || type == HUB_INIT3)
+		device_unlock(hub->intfdev);
+
+	kref_put(&hub->kref, hub_release);
 }
 
 /* Implement the continuations for the delays above */
@@ -2980,14 +2996,14 @@ int usb_port_suspend(struct usb_device *udev, pm_message_t msg)
 	int		port1 = udev->portnum;
 	int		status;
 	bool		really_suspend = true;
-#ifndef CONFIG_MDM_HSIC_PM
+
 	/* enable remote wakeup when appropriate; this lets the device
 	 * wake up the upstream hub (including maybe the root hub).
 	 *
 	 * NOTE:  OTG devices may issue remote wakeup (or SRP) even when
 	 * we don't explicitly enable it here.
 	 */
-	if (udev->do_remote_wakeup) {
+	if (udev->do_remote_wakeup && !(udev->quirks & USB_QUIRK_IGNORE_REMOTE_WAKEUP)){
 		if (!hub_is_superspeed(hub->hdev)) {
 			status = usb_control_msg(udev, usb_sndctrlpipe(udev, 0),
 					USB_REQ_SET_FEATURE, USB_RECIP_DEVICE,
@@ -3017,7 +3033,7 @@ int usb_port_suspend(struct usb_device *udev, pm_message_t msg)
 				goto err_wakeup;
 		}
 	}
-#endif
+
 	/* disable USB2 hardware LPM */
 	if (udev->usb2_hw_lpm_enabled == 1)
 		usb_set_usb2_hardware_lpm(udev, 0);
@@ -3051,12 +3067,11 @@ int usb_port_suspend(struct usb_device *udev, pm_message_t msg)
 	 * descendants is enabled for remote wakeup.
 	 */
 	else if (PMSG_IS_AUTO(msg) || wakeup_enabled_descendants(udev) > 0) {
-#ifdef CONFIG_MDM_HSIC_PM
-		status = 0;
-#else
-		status = set_port_feature(hub->hdev, port1,
-				USB_PORT_FEAT_SUSPEND);
-#endif
+		if (udev->quirks & USB_QUIRK_IGNORE_REMOTE_WAKEUP)
+			status = 0;
+		else
+			status = set_port_feature(hub->hdev, port1,
+					USB_PORT_FEAT_SUSPEND);
 	} else {
 		really_suspend = false;
 		status = 0;
@@ -3088,9 +3103,7 @@ int usb_port_suspend(struct usb_device *udev, pm_message_t msg)
 						USB_INTRF_FUNC_SUSPEND, 0,
 						NULL, 0, USB_CTRL_SET_TIMEOUT);
 		}
-#ifndef CONFIG_MDM_HSIC_PM
 err_wakeup:
-#endif
 
 		/* System sleep transitions should never fail */
 		if (!PMSG_IS_AUTO(msg))
diff --git a/drivers/usb/core/quirks.c b/drivers/usb/core/quirks.c
index b986bf0..00fe312 100755
--- a/drivers/usb/core/quirks.c
+++ b/drivers/usb/core/quirks.c
@@ -156,7 +156,7 @@ static const struct usb_device_id usb_quirk_list[] = {
 
 #if defined(CONFIG_MDM_HSIC_PM)
 	/* Qualcomm MDM9x35 */
-	{ USB_DEVICE(0x05c6, 0x909E), .driver_info = USB_QUIRK_HSIC_TUNE},
+	{ USB_DEVICE(0x05c6, 0x909E), .driver_info = USB_QUIRK_HSIC_TUNE | USB_QUIRK_IGNORE_REMOTE_WAKEUP },
 #endif
 	{ }  /* terminating entry must be last */
 };
diff --git a/drivers/video/exynos/decon/decon_core.c b/drivers/video/exynos/decon/decon_core.c
index a681333..e5b97f1 100755
--- a/drivers/video/exynos/decon/decon_core.c
+++ b/drivers/video/exynos/decon/decon_core.c
@@ -4092,6 +4092,11 @@ static ssize_t decon_fb_read(struct fb_info *info, char __user *buf,
 	return 0;
 }
 
+static ssize_t decon_fb_write(struct fb_info *info, const char __user *buf,
+		size_t count, loff_t *ppos)
+{
+	return 0;
+}
 
 static int decon_ioctl(struct fb_info *info, unsigned int cmd,
 			unsigned long arg)
@@ -4272,6 +4277,7 @@ static struct fb_ops decon_fb_ops = {
 	.fb_imageblit   = cfb_imageblit,
 	.fb_ioctl	= decon_ioctl,
 	.fb_read	= decon_fb_read,
+	.fb_write	= decon_fb_write,
 	.fb_pan_display	= decon_pan_display,
 	.fb_mmap	= decon_mmap,
 	.fb_release	= decon_release,
diff --git a/drivers/video/exynos/decon/dsim_drv.c b/drivers/video/exynos/decon/dsim_drv.c
index 158f6e0..9290607 100755
--- a/drivers/video/exynos/decon/dsim_drv.c
+++ b/drivers/video/exynos/decon/dsim_drv.c
@@ -550,8 +550,9 @@ int dsim_read_data(struct dsim_device *dsim, u32 data_id,
 	case MIPI_DSI_RX_GENERIC_SHORT_READ_RESPONSE_1BYTE:
 	case MIPI_DSI_RX_GENERIC_SHORT_READ_RESPONSE_2BYTE:
 		dev_dbg(dsim->dev, "Short Packet was received from LCD module.\n");
-		for (i = 0; i <= count; i++)
+		for (i = 0; i < count; i++)
 			buf[i] = (rx_fifo >> (8 + i * 8)) & 0xff;
+		rx_size = count;
 		break;
 	case MIPI_DSI_RX_DCS_LONG_READ_RESPONSE:
 	case MIPI_DSI_RX_GENERIC_LONG_READ_RESPONSE:
diff --git a/drivers/video/exynos/decon/panels/dsim_backlight_dynamic.c b/drivers/video/exynos/decon/panels/dsim_backlight_dynamic.c
index 63c7d80..0e2a7da 100755
--- a/drivers/video/exynos/decon/panels/dsim_backlight_dynamic.c
+++ b/drivers/video/exynos/decon/panels/dsim_backlight_dynamic.c
@@ -537,6 +537,11 @@ int dsim_panel_set_brightness(struct dsim_device *dsim, int force)
 		acutal_br = real_br = get_actual_br_value(dsim, panel->br_index);
 		panel->interpolation = 1;
 		panel->acl_enable = ACL_OPR_8P;
+
+		if (panel->state != PANEL_STATE_RESUMED) {
+			dsim_info("%s : panel is not active state..\n", __func__);
+			goto set_br_exit;
+		}
 		goto set_brightness;
 	} else {
 		panel->interpolation = 0;
diff --git a/fs/ecryptfs/ecryptfs_dek.c b/fs/ecryptfs/ecryptfs_dek.c
index f1e2f7b..51fe607 100755
--- a/fs/ecryptfs/ecryptfs_dek.c
+++ b/fs/ecryptfs/ecryptfs_dek.c
@@ -204,6 +204,9 @@ int parse_dek_packet(char *data,
 	char temp_comm[PKG_NAME_SIZE]; //test
 	int temp_euid;
 
+	if (crypt_stat->file_version == 0)
+		return -EPERM;
+
 	(*packet_size) = 0;
 
 	if (data[(*packet_size)++] != ECRYPTFS_DEK_PACKET_TYPE) {
@@ -233,8 +236,12 @@ int parse_dek_packet(char *data,
 
 		crypt_stat->sdp_dek.type = get_unaligned_be32(data + *packet_size);
 		(*packet_size) += 4;
+		if(crypt_stat->sdp_dek.type < 0 || crypt_stat->sdp_dek.type > 6)
+			return -EINVAL;
 		crypt_stat->sdp_dek.len = get_unaligned_be32(data + *packet_size);
 		(*packet_size) += 4;
+		if(crypt_stat->sdp_dek.len <= 0 || crypt_stat->sdp_dek.len > DEK_MAXLEN)
+			return -EFAULT;
 		memcpy(crypt_stat->sdp_dek.buf, &data[*packet_size], crypt_stat->sdp_dek.len);
 		(*packet_size) += crypt_stat->sdp_dek.len;
 	}
diff --git a/fs/ecryptfs/keystore.c b/fs/ecryptfs/keystore.c
index 45a2415..5e87868 100755
--- a/fs/ecryptfs/keystore.c
+++ b/fs/ecryptfs/keystore.c
@@ -1911,7 +1911,7 @@ int ecryptfs_parse_packet_set(struct ecryptfs_crypt_stat *crypt_stat,
 					&packet_size);
 			if (rc) {
 				ecryptfs_printk(KERN_ERR, "Error parsing "
-						"dek packet\n");
+						"dek packet %d\n", rc);
 			rc = -EIO;
 			goto out_wipe_list;
 			}
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index d4a878b..ac9ed6c 100755
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -4462,14 +4462,14 @@ static int ext4_do_update_inode(handle_t *handle,
  * Fix up interoperability with old kernels. Otherwise, old inodes get
  * re-used with the upper 16 bits of the uid/gid intact
  */
-		if (!ei->i_dtime) {
+		if (ei->i_dtime && list_empty(&ei->i_orphan)) {
+			raw_inode->i_uid_high = 0;
+			raw_inode->i_gid_high = 0;
+		}else {
 			raw_inode->i_uid_high =
 				cpu_to_le16(high_16_bits(i_uid));
 			raw_inode->i_gid_high =
 				cpu_to_le16(high_16_bits(i_gid));
-		} else {
-			raw_inode->i_uid_high = 0;
-			raw_inode->i_gid_high = 0;
 		}
 	} else {
 		raw_inode->i_uid_low = cpu_to_le16(fs_high2lowuid(i_uid));
diff --git a/fs/namei.c b/fs/namei.c
index 475d1e2..902ef59 100755
--- a/fs/namei.c
+++ b/fs/namei.c
@@ -3382,6 +3382,8 @@ static long do_rmdir(int dfd, const char __user *pathname)
 	struct dentry *dentry;
 	struct nameidata nd;
 	unsigned int lookup_flags = 0;
+	char *path_buf = NULL;
+	char *propagate_path = NULL;
 retry:
 	name = user_path_parent(dfd, pathname, &nd, lookup_flags);
 	if (IS_ERR(name))
@@ -3416,11 +3418,23 @@ retry:
 	error = security_path_rmdir(&nd.path, dentry);
 	if (error)
 		goto exit3;
+	if (nd.path.dentry->d_sb->s_op->unlink_callback) {
+		path_buf = kmalloc(PATH_MAX, GFP_KERNEL);
+		propagate_path = dentry_path_raw(dentry, path_buf, PATH_MAX);
+	}
 	error = vfs_rmdir(nd.path.dentry->d_inode, dentry);
 exit3:
 	dput(dentry);
 exit2:
 	mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
+	if (path_buf && !error) {
+		nd.path.dentry->d_sb->s_op->unlink_callback(nd.path.dentry->d_sb,
+			propagate_path);
+	}
+	if (path_buf) {
+		kfree(path_buf);
+		path_buf = NULL;
+	}
 	mnt_drop_write(nd.path.mnt);
 exit1:
 	path_put(&nd.path);
@@ -3524,7 +3538,10 @@ exit2:
 	mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
 	if (path_buf && !error) {
 		inode->i_sb->s_op->unlink_callback(inode->i_sb, propagate_path);
+	}
+	if (path_buf) {
 		kfree(path_buf);
+		path_buf = NULL;
 	}
 	if (inode)
 		iput(inode);	/* truncate the inode here */
diff --git a/fs/pipe.c b/fs/pipe.c
index 50267e6..c281867 100755
--- a/fs/pipe.c
+++ b/fs/pipe.c
@@ -39,6 +39,12 @@ unsigned int pipe_max_size = 1048576;
  */
 unsigned int pipe_min_size = PAGE_SIZE;
 
+/* Maximum allocatable pages per user. Hard limit is unset by default, soft
+ * matches default values.
+ */
+unsigned long pipe_user_pages_hard;
+unsigned long pipe_user_pages_soft = PIPE_DEF_BUFFERS * INR_OPEN_CUR;
+
 /*
  * We use a start+len construction, which provides full use of the 
  * allocated memory.
@@ -794,20 +800,49 @@ pipe_fasync(int fd, struct file *filp, int on)
 	return retval;
 }
 
+static void account_pipe_buffers(struct pipe_inode_info *pipe,
+                                 unsigned long old, unsigned long new)
+{
+	atomic_long_add(new - old, &pipe->user->pipe_bufs);
+}
+
+static bool too_many_pipe_buffers_soft(struct user_struct *user)
+{
+	return pipe_user_pages_soft &&
+	       atomic_long_read(&user->pipe_bufs) >= pipe_user_pages_soft;
+}
+
+static bool too_many_pipe_buffers_hard(struct user_struct *user)
+{
+	return pipe_user_pages_hard &&
+	       atomic_long_read(&user->pipe_bufs) >= pipe_user_pages_hard;
+}
+
 struct pipe_inode_info *alloc_pipe_info(void)
 {
 	struct pipe_inode_info *pipe;
 
 	pipe = kzalloc(sizeof(struct pipe_inode_info), GFP_KERNEL);
 	if (pipe) {
-		pipe->bufs = kzalloc(sizeof(struct pipe_buffer) * PIPE_DEF_BUFFERS, GFP_KERNEL);
+		unsigned long pipe_bufs = PIPE_DEF_BUFFERS;
+		struct user_struct *user = get_current_user();
+
+		if (!too_many_pipe_buffers_hard(user)) {
+			if (too_many_pipe_buffers_soft(user))
+				pipe_bufs = 1;
+			pipe->bufs = kzalloc(sizeof(struct pipe_buffer) * pipe_bufs, GFP_KERNEL);
+		}
+
 		if (pipe->bufs) {
 			init_waitqueue_head(&pipe->wait);
 			pipe->r_counter = pipe->w_counter = 1;
-			pipe->buffers = PIPE_DEF_BUFFERS;
+			pipe->buffers = pipe_bufs;
+			pipe->user = user;
+			account_pipe_buffers(pipe, 0, pipe_bufs);
 			mutex_init(&pipe->mutex);
 			return pipe;
 		}
+		free_uid(user);
 		kfree(pipe);
 	}
 
@@ -818,6 +853,8 @@ void free_pipe_info(struct pipe_inode_info *pipe)
 {
 	int i;
 
+	account_pipe_buffers(pipe, pipe->buffers, 0);
+	free_uid(pipe->user);
 	for (i = 0; i < pipe->buffers; i++) {
 		struct pipe_buffer *buf = pipe->bufs + i;
 		if (buf->ops)
@@ -1208,6 +1245,7 @@ static long pipe_set_size(struct pipe_inode_info *pipe, unsigned long nr_pages)
 			memcpy(bufs + head, pipe->bufs, tail * sizeof(struct pipe_buffer));
 	}
 
+	account_pipe_buffers(pipe, pipe->buffers, nr_pages);
 	pipe->curbuf = 0;
 	kfree(pipe->bufs);
 	pipe->bufs = bufs;
@@ -1279,6 +1317,11 @@ long pipe_fcntl(struct file *file, unsigned int cmd, unsigned long arg)
 		if (!capable(CAP_SYS_RESOURCE) && size > pipe_max_size) {
 			ret = -EPERM;
 			goto out;
+		} else if ((too_many_pipe_buffers_hard(pipe->user) ||
+			    too_many_pipe_buffers_soft(pipe->user)) &&
+		           !capable(CAP_SYS_RESOURCE) && !capable(CAP_SYS_ADMIN)) {
+			ret = -EPERM;
+			goto out;
 		}
 		ret = pipe_set_size(pipe, nr_pages);
 		break;
diff --git a/fs/proc/base.c b/fs/proc/base.c
index 9a1e051..2963403 100755
--- a/fs/proc/base.c
+++ b/fs/proc/base.c
@@ -818,7 +818,8 @@ static ssize_t environ_read(struct file *file, char __user *buf,
 	int ret = 0;
 	struct mm_struct *mm = file->private_data;
 
-	if (!mm)
+	/* Ensure the process spawned far enough to have an environment. */
+	if (!mm || !mm->env_end)
 		return 0;
 
 	page = (char *)__get_free_page(GFP_TEMPORARY);
diff --git a/fs/sdcardfs/derived_perm.c b/fs/sdcardfs/derived_perm.c
index 767a33c..76f496e 100755
--- a/fs/sdcardfs/derived_perm.c
+++ b/fs/sdcardfs/derived_perm.c
@@ -90,7 +90,11 @@ void get_derived_permission(struct dentry *parent, struct dentry *dentry)
 				/* App-specific directories inside; let anyone traverse */
 				info->perm = PERM_ANDROID;
 				info->under_android = true;
-			}
+			} else if (!strcasecmp(dentry->d_name.name, "knox")) {
+				info->perm = PERM_ANDROID_KNOX;
+				info->d_gid = AID_SDCARD_R;
+				info->under_android = false;
+           		}
 			break;
 		case PERM_ANDROID:
 			if (!strcasecmp(dentry->d_name.name, "data")) {
@@ -116,6 +120,47 @@ void get_derived_permission(struct dentry *parent, struct dentry *dentry)
 				info->d_uid = multiuser_get_uid(parent_info->userid, appid);
 			}
 			break;
+		/** KNOX permission */
+		case PERM_ANDROID_KNOX:
+			info->perm = PERM_ANDROID_KNOX_USER;
+	        	info->userid = simple_strtoul(dentry->d_name.name, NULL, 10);
+	        	info->d_gid = AID_SDCARD_R;
+	        	info->under_android = false;
+	        break;
+
+		case PERM_ANDROID_KNOX_USER:
+			if (!strcasecmp(dentry->d_name.name, "Android")) {
+					info->perm = PERM_ANDROID_KNOX_ANDROID;
+					info->under_android = false;
+			}
+		break;
+		case PERM_ANDROID_KNOX_ANDROID:
+			if (!strcasecmp(dentry->d_name.name, "data")) {
+				info->perm = PERM_ANDROID_KNOX_DATA;
+				info->under_android = false;
+			} else if (!strcasecmp(dentry->d_name.name, "shared")) {
+			info->perm = PERM_ANDROID_KNOX_SHARED;
+			info->d_gid = AID_SDCARD_RW;
+			info->d_uid = multiuser_get_uid(parent_info->userid, 0);
+			info->under_android = false;
+		}
+		break;
+
+		case PERM_ANDROID_KNOX_SHARED:
+		break;
+
+		case PERM_ANDROID_KNOX_DATA:
+			appid = get_appid(sbi->pkgl_id, dentry->d_name.name);
+			info->perm = PERM_ANDROID_KNOX_PACKAGE_DATA;
+		if (appid != 0) {
+			info->d_uid = multiuser_get_uid(parent_info->userid, appid);
+		} else {
+			info->d_uid = multiuser_get_uid(parent_info->userid, 0);
+		}
+			info->under_android = false;
+		break;
+		case PERM_ANDROID_KNOX_PACKAGE_DATA:
+		break;
 	}
 } 
 
@@ -146,6 +191,9 @@ void fix_derived_permission(struct inode *inode) {
         /* Top of multi-user view should always be visible to ensure
          * secondary users can traverse inside. */
 		visible_mode = 00711;
+	} else if (info->perm == PERM_ANDROID_KNOX_PACKAGE_DATA
+	        && !info->under_android) {
+		visible_mode = visible_mode & ~00006;
 	} else if (info->under_android) {
 		if (info->d_gid == AID_SDCARD_RW) {
 			visible_mode = visible_mode & ~00006;
diff --git a/fs/sdcardfs/sdcardfs.h b/fs/sdcardfs/sdcardfs.h
index 01c0dbd..0464c08 100755
--- a/fs/sdcardfs/sdcardfs.h
+++ b/fs/sdcardfs/sdcardfs.h
@@ -121,6 +121,18 @@ typedef enum {
 	PERM_ANDROID_OBB,
 	/* This node is "/Android/media" */
 	PERM_ANDROID_MEDIA,
+	/* knox folder */
+	PERM_ANDROID_KNOX,
+	/* knox user folder*/
+	PERM_ANDROID_KNOX_USER,
+	/* knox Android folder*/
+	PERM_ANDROID_KNOX_ANDROID,
+	/* knox shared folder */
+	PERM_ANDROID_KNOX_SHARED,
+	/* knox data folder */
+	PERM_ANDROID_KNOX_DATA,
+	/* knox package data folder */
+	PERM_ANDROID_KNOX_PACKAGE_DATA
 } perm_t;
 
 typedef enum {
diff --git a/include/linux/ipv6.h b/include/linux/ipv6.h
index ebc6306..b1199a2 100755
--- a/include/linux/ipv6.h
+++ b/include/linux/ipv6.h
@@ -219,7 +219,7 @@ struct ipv6_pinfo {
 	struct ipv6_ac_socklist	*ipv6_ac_list;
 	struct ipv6_fl_socklist __rcu *ipv6_fl_list;
 
-	struct ipv6_txoptions	*opt;
+	struct ipv6_txoptions __rcu	*opt;
 	struct sk_buff		*pktoptions;
 	struct sk_buff		*rxpmtu;
 	struct {
diff --git a/include/linux/mm.h b/include/linux/mm.h
index 10aad70..952877a 100755
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -1718,6 +1718,7 @@ static inline struct page *follow_page(struct vm_area_struct *vma,
 #define FOLL_HWPOISON	0x100	/* check page is hwpoisoned */
 #define FOLL_NUMA	0x200	/* force NUMA hinting page fault */
 #define FOLL_MIGRATION	0x400	/* wait for page to replace migration entry */
+#define FOLL_COW	0x4000	/* internal GUP flag */
 
 typedef int (*pte_fn_t)(pte_t *pte, pgtable_t token, unsigned long addr,
 			void *data);
diff --git a/include/linux/pipe_fs_i.h b/include/linux/pipe_fs_i.h
index ab57526..b3374f6 100755
--- a/include/linux/pipe_fs_i.h
+++ b/include/linux/pipe_fs_i.h
@@ -42,6 +42,7 @@ struct pipe_buffer {
  *	@fasync_readers: reader side fasync
  *	@fasync_writers: writer side fasync
  *	@bufs: the circular array of pipe buffers
+ *	@user: the user who created this pipe
  **/
 struct pipe_inode_info {
 	struct mutex mutex;
@@ -57,6 +58,7 @@ struct pipe_inode_info {
 	struct fasync_struct *fasync_readers;
 	struct fasync_struct *fasync_writers;
 	struct pipe_buffer *bufs;
+	struct user_struct *user;
 };
 
 /*
@@ -140,6 +142,8 @@ void pipe_unlock(struct pipe_inode_info *);
 void pipe_double_lock(struct pipe_inode_info *, struct pipe_inode_info *);
 
 extern unsigned int pipe_max_size, pipe_min_size;
+extern unsigned long pipe_user_pages_hard;
+extern unsigned long pipe_user_pages_soft;
 int pipe_proc_fn(struct ctl_table *, int, void __user *, size_t *, loff_t *);
 
 
diff --git a/include/linux/sched.h b/include/linux/sched.h
index fc3e1a1..6c7935b 100755
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -677,6 +677,7 @@ struct user_struct {
 #endif
 	unsigned long locked_shm; /* How many pages of mlocked shm ? */
 	unsigned long unix_inflight;	/* How many files in flight in unix sockets */
+	atomic_long_t pipe_bufs;  /* how many pages are allocated in pipe buffers */
 
 #ifdef CONFIG_KEYS
 	struct key *uid_keyring;	/* UID specific keyring */
diff --git a/include/net/af_unix.h b/include/net/af_unix.h
index c9151b6..17fa3ec 100755
--- a/include/net/af_unix.h
+++ b/include/net/af_unix.h
@@ -63,6 +63,7 @@ struct unix_sock {
 #define UNIX_GC_CANDIDATE	0
 #define UNIX_GC_MAYBE_CYCLE	1
 	struct socket_wq	peer_wq;
+	wait_queue_t		peer_wake;
 };
 #define unix_sk(__sk) ((struct unix_sock *)__sk)
 
diff --git a/include/net/ipv6.h b/include/net/ipv6.h
index 27e9ba4..48c7997 100755
--- a/include/net/ipv6.h
+++ b/include/net/ipv6.h
@@ -203,6 +203,7 @@ extern rwlock_t ip6_ra_lock;
  */
 
 struct ipv6_txoptions {
+	atomic_t		refcnt;
 	/* Length of this structure */
 	int			tot_len;
 
@@ -215,7 +216,7 @@ struct ipv6_txoptions {
 	struct ipv6_opt_hdr	*dst0opt;
 	struct ipv6_rt_hdr	*srcrt;	/* Routing Header */
 	struct ipv6_opt_hdr	*dst1opt;
-
+	struct rcu_head		rcu;
 	/* Option buffer, as read by IPV6_PKTOPTIONS, starts here. */
 };
 
@@ -246,6 +247,24 @@ struct ipv6_fl_socklist {
 	struct rcu_head			rcu;
 };
 
+static inline struct ipv6_txoptions *txopt_get(const struct ipv6_pinfo *np)
+{
+	struct ipv6_txoptions *opt;
+
+	rcu_read_lock();
+	opt = rcu_dereference(np->opt);
+	if (opt && !atomic_inc_not_zero(&opt->refcnt))
+		opt = NULL;
+	rcu_read_unlock();
+	return opt;
+}
+
+static inline void txopt_put(struct ipv6_txoptions *opt)
+{
+	if (opt && atomic_dec_and_test(&opt->refcnt))
+		kfree_rcu(opt, rcu);
+}
+
 extern struct ip6_flowlabel	*fl6_sock_lookup(struct sock *sk, __be32 label);
 extern struct ipv6_txoptions	*fl6_merge_options(struct ipv6_txoptions * opt_space,
 						   struct ip6_flowlabel * fl,
diff --git a/include/net/tcp.h b/include/net/tcp.h
index 136397a..2d3e8d6 100755
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -1607,6 +1607,8 @@ static inline void tcp_check_send_head(struct sock *sk, struct sk_buff *skb_unli
 {
 	if (sk->sk_send_head == skb_unlinked)
 		sk->sk_send_head = NULL;
+	if (tcp_sk(sk)->highest_sack == skb_unlinked)
+		tcp_sk(sk)->highest_sack = NULL;
 }
 
 static inline void tcp_init_send_head(struct sock *sk)
diff --git a/kernel/auditsc.c b/kernel/auditsc.c
index f684e3a..1688c0c 100755
--- a/kernel/auditsc.c
+++ b/kernel/auditsc.c
@@ -70,6 +70,7 @@
 #include <linux/compat.h>
 #include <linux/ctype.h>
 #include <asm/unistd.h>
+#include <linux/uaccess.h>
 
 #include "audit.h"
 
@@ -78,7 +79,8 @@
 #define AUDITSC_SUCCESS 1
 #define AUDITSC_FAILURE 2
 
-/* no execve audit message should be longer than this (userspace limits) */
+/* no execve audit message should be longer than this (userspace limits),
+ * see the note near the top of audit_log_execve_info() about this value */
 #define MAX_EXECVE_AUDIT_LEN 7500
 
 /* max length to print of cmdline/proctitle value during audit */
@@ -1023,189 +1025,184 @@ static int audit_log_pid_context(struct audit_context *context, pid_t pid,
 	return rc;
 }
 
-/*
- * to_send and len_sent accounting are very loose estimates.  We aren't
- * really worried about a hard cap to MAX_EXECVE_AUDIT_LEN so much as being
- * within about 500 bytes (next page boundary)
- *
- * why snprintf?  an int is up to 12 digits long.  if we just assumed when
- * logging that a[%d]= was going to be 16 characters long we would be wasting
- * space in every audit message.  In one 7500 byte message we can log up to
- * about 1000 min size arguments.  That comes down to about 50% waste of space
- * if we didn't do the snprintf to find out how long arg_num_len was.
- */
-static int audit_log_single_execve_arg(struct audit_context *context,
-					struct audit_buffer **ab,
-					int arg_num,
-					size_t *len_sent,
-					const char __user *p,
-					char *buf)
-{
-	char arg_num_len_buf[12];
-	const char __user *tmp_p = p;
-	/* how many digits are in arg_num? 5 is the length of ' a=""' */
-	size_t arg_num_len = snprintf(arg_num_len_buf, 12, "%d", arg_num) + 5;
-	size_t len, len_left, to_send;
-	size_t max_execve_audit_len = MAX_EXECVE_AUDIT_LEN;
-	unsigned int i, has_cntl = 0, too_long = 0;
-	int ret;
-
-	/* strnlen_user includes the null we don't want to send */
-	len_left = len = strnlen_user(p, MAX_ARG_STRLEN) - 1;
-
-	/*
-	 * We just created this mm, if we can't find the strings
-	 * we just copied into it something is _very_ wrong. Similar
-	 * for strings that are too long, we should not have created
-	 * any.
-	 */
-	if (unlikely((len == -1) || len > MAX_ARG_STRLEN - 1)) {
-		WARN_ON(1);
-		send_sig(SIGKILL, current, 0);
-		return -1;
-	}
-
-	/* walk the whole argument looking for non-ascii chars */
-	do {
-		if (len_left > MAX_EXECVE_AUDIT_LEN)
-			to_send = MAX_EXECVE_AUDIT_LEN;
-		else
-			to_send = len_left;
-		ret = copy_from_user(buf, tmp_p, to_send);
-		/*
-		 * There is no reason for this copy to be short. We just
-		 * copied them here, and the mm hasn't been exposed to user-
-		 * space yet.
-		 */
-		if (ret) {
-			WARN_ON(1);
-			send_sig(SIGKILL, current, 0);
-			return -1;
-		}
-		buf[to_send] = '\0';
-		has_cntl = audit_string_contains_control(buf, to_send);
-		if (has_cntl) {
-			/*
-			 * hex messages get logged as 2 bytes, so we can only
-			 * send half as much in each message
-			 */
-			max_execve_audit_len = MAX_EXECVE_AUDIT_LEN / 2;
-			break;
-		}
-		len_left -= to_send;
-		tmp_p += to_send;
-	} while (len_left > 0);
-
-	len_left = len;
-
-	if (len > max_execve_audit_len)
-		too_long = 1;
-
-	/* rewalk the argument actually logging the message */
-	for (i = 0; len_left > 0; i++) {
-		int room_left;
-
-		if (len_left > max_execve_audit_len)
-			to_send = max_execve_audit_len;
-		else
-			to_send = len_left;
-
-		/* do we have space left to send this argument in this ab? */
-		room_left = MAX_EXECVE_AUDIT_LEN - arg_num_len - *len_sent;
-		if (has_cntl)
-			room_left -= (to_send * 2);
-		else
-			room_left -= to_send;
-		if (room_left < 0) {
-			*len_sent = 0;
-			audit_log_end(*ab);
-			*ab = audit_log_start(context, GFP_KERNEL, AUDIT_EXECVE);
-			if (!*ab)
-				return 0;
-		}
-
-		/*
-		 * first record needs to say how long the original string was
-		 * so we can be sure nothing was lost.
-		 */
-		if ((i == 0) && (too_long))
-			audit_log_format(*ab, " a%d_len=%zu", arg_num,
-					 has_cntl ? 2*len : len);
-
-		/*
-		 * normally arguments are small enough to fit and we already
-		 * filled buf above when we checked for control characters
-		 * so don't bother with another copy_from_user
-		 */
-		if (len >= max_execve_audit_len)
-			ret = copy_from_user(buf, p, to_send);
-		else
-			ret = 0;
-		if (ret) {
-			WARN_ON(1);
-			send_sig(SIGKILL, current, 0);
-			return -1;
-		}
-		buf[to_send] = '\0';
-
-		/* actually log it */
-		audit_log_format(*ab, " a%d", arg_num);
-		if (too_long)
-			audit_log_format(*ab, "[%d]", i);
-		audit_log_format(*ab, "=");
-		if (has_cntl)
-			audit_log_n_hex(*ab, buf, to_send);
-		else
-			audit_log_string(*ab, buf);
-
-		p += to_send;
-		len_left -= to_send;
-		*len_sent += arg_num_len;
-		if (has_cntl)
-			*len_sent += to_send * 2;
-		else
-			*len_sent += to_send;
-	}
-	/* include the null we didn't log */
-	return len + 1;
-}
-
 static void audit_log_execve_info(struct audit_context *context,
 				  struct audit_buffer **ab,
 				  struct audit_aux_data_execve *axi)
 {
-	int i, len;
-	size_t len_sent = 0;
-	const char __user *p;
+	long len_max;
+	long len_rem;
+	long len_full;
+	long len_buf;
+	long len_abuf;
+	long len_tmp;
+	bool require_data;
+	bool encode;
+	unsigned int iter;
+	unsigned int arg;
+	char *buf_head;
 	char *buf;
+	const char __user *p;
+
+	/* NOTE: this buffer needs to be large enough to hold all the non-arg
+	 *       data we put in the audit record for this argument (see the
+	 *       code below) ... at this point in time 96 is plenty */
+	char abuf[96];
 
 	if (axi->mm != current->mm)
 		return; /* execve failed, no additional info */
 
 	p = (const char __user *)axi->mm->arg_start;
 
-	audit_log_format(*ab, "argc=%d", axi->argc);
-
-	/*
-	 * we need some kernel buffer to hold the userspace args.  Just
-	 * allocate one big one rather than allocating one of the right size
-	 * for every single argument inside audit_log_single_execve_arg()
-	 * should be <8k allocation so should be pretty safe.
-	 */
-	buf = kmalloc(MAX_EXECVE_AUDIT_LEN + 1, GFP_KERNEL);
-	if (!buf) {
-		audit_panic("out of memory for argv string\n");
+	/* NOTE: we set MAX_EXECVE_AUDIT_LEN to a rather arbitrary limit, the
+	 *       current value of 7500 is not as important as the fact that it
+	 *       is less than 8k, a setting of 7500 gives us plenty of wiggle
+	 *       room if we go over a little bit in the logging below */
+	WARN_ON_ONCE(MAX_EXECVE_AUDIT_LEN > 7500);
+	len_max = MAX_EXECVE_AUDIT_LEN;
+
+	/* scratch buffer to hold the userspace args */
+	buf_head = kmalloc(MAX_EXECVE_AUDIT_LEN + 1, GFP_KERNEL);
+	if (!buf_head) {
+		audit_panic("out of memory for argv string");
 		return;
 	}
+	buf = buf_head;
 
-	for (i = 0; i < axi->argc; i++) {
-		len = audit_log_single_execve_arg(context, ab, i,
-						  &len_sent, p, buf);
-		if (len <= 0)
-			break;
-		p += len;
-	}
-	kfree(buf);
+	audit_log_format(*ab, "argc=%d", axi->argc);
+
+	len_rem = len_max;
+	len_buf = 0;
+	len_full = 0;
+	require_data = true;
+	encode = false;
+	iter = 0;
+	arg = 0;
+	do {
+		/* NOTE: we don't ever want to trust this value for anything
+		 *       serious, but the audit record format insists we
+		 *       provide an argument length for really long arguments,
+		 *       e.g. > MAX_EXECVE_AUDIT_LEN, so we have no choice but
+		 *       to use strncpy_from_user() to obtain this value for
+		 *       recording in the log, although we don't use it
+		 *       anywhere here to avoid a double-fetch problem */
+		if (len_full == 0)
+			len_full = strnlen_user(p, MAX_ARG_STRLEN) - 1;
+
+		/* read more data from userspace */
+		if (require_data) {
+			/* can we make more room in the buffer? */
+			if (buf != buf_head) {
+				memmove(buf_head, buf, len_buf);
+				buf = buf_head;
+			}
+
+			/* fetch as much as we can of the argument */
+			len_tmp = strncpy_from_user(&buf_head[len_buf], p,
+						    len_max - len_buf);
+			if (len_tmp == -EFAULT) {
+				/* unable to copy from userspace */
+				send_sig(SIGKILL, current, 0);
+				goto out;
+			} else if (len_tmp == (len_max - len_buf)) {
+				/* buffer is not large enough */
+				require_data = true;
+				/* NOTE: if we are going to span multiple
+				 *       buffers force the encoding so we stand
+				 *       a chance at a sane len_full value and
+				 *       consistent record encoding */
+				encode = true;
+				len_full = len_full * 2;
+				p += len_tmp;
+			} else {
+				require_data = false;
+				if (!encode)
+					encode = audit_string_contains_control(
+								buf, len_tmp);
+				/* try to use a trusted value for len_full */
+				if (len_full < len_max)
+					len_full = (encode ?
+						    len_tmp * 2 : len_tmp);
+				p += len_tmp + 1;
+			}
+			len_buf += len_tmp;
+			buf_head[len_buf] = '\0';
+
+			/* length of the buffer in the audit record? */
+			len_abuf = (encode ? len_buf * 2 : len_buf + 2);
+		}
+
+		/* write as much as we can to the audit log */
+		if (len_buf > 0) {
+			/* NOTE: some magic numbers here - basically if we
+			 *       can't fit a reasonable amount of data into the
+			 *       existing audit buffer, flush it and start with
+			 *       a new buffer */
+			if ((sizeof(abuf) + 8) > len_rem) {
+				len_rem = len_max;
+				audit_log_end(*ab);
+				*ab = audit_log_start(context,
+						      GFP_KERNEL, AUDIT_EXECVE);
+				if (!*ab)
+					goto out;
+			}
+
+			/* create the non-arg portion of the arg record */
+			len_tmp = 0;
+			if (require_data || (iter > 0) ||
+			    ((len_abuf + sizeof(abuf)) > len_rem)) {
+				if (iter == 0) {
+					len_tmp += snprintf(&abuf[len_tmp],
+							sizeof(abuf) - len_tmp,
+							" a%d_len=%lu",
+							arg, len_full);
+				}
+				len_tmp += snprintf(&abuf[len_tmp],
+						    sizeof(abuf) - len_tmp,
+						    " a%d[%d]=", arg, iter++);
+			} else
+				len_tmp += snprintf(&abuf[len_tmp],
+						    sizeof(abuf) - len_tmp,
+						    " a%d=", arg);
+			WARN_ON(len_tmp >= sizeof(abuf));
+			abuf[sizeof(abuf) - 1] = '\0';
+
+			/* log the arg in the audit record */
+			audit_log_format(*ab, "%s", abuf);
+			len_rem -= len_tmp;
+			len_tmp = len_buf;
+			if (encode) {
+				if (len_abuf > len_rem)
+					len_tmp = len_rem / 2; /* encoding */
+				audit_log_n_hex(*ab, buf, len_tmp);
+				len_rem -= len_tmp * 2;
+				len_abuf -= len_tmp * 2;
+			} else {
+				if (len_abuf > len_rem)
+					len_tmp = len_rem - 2; /* quotes */
+				audit_log_n_string(*ab, buf, len_tmp);
+				len_rem -= len_tmp + 2;
+				/* don't subtract the "2" because we still need
+				 * to add quotes to the remaining string */
+				len_abuf -= len_tmp;
+			}
+			len_buf -= len_tmp;
+			buf += len_tmp;
+		}
+
+		/* ready to move to the next argument? */
+		if ((len_buf == 0) && !require_data) {
+			arg++;
+			iter = 0;
+			len_full = 0;
+			require_data = true;
+			encode = false;
+		}
+	} while (arg < axi->argc);
+
+	/* NOTE: the caller handles the final audit_log_end() call */
+
+out:
+	kfree(buf_head);
 }
 
 static void show_special(struct audit_context *context, int *call_panic)
diff --git a/kernel/cgroup.c b/kernel/cgroup.c
index 6c277e4..7eaad26 100755
--- a/kernel/cgroup.c
+++ b/kernel/cgroup.c
@@ -5474,7 +5474,7 @@ static int cgroup_css_links_read(struct cgroup *cont,
 		struct css_set *cg = link->cg;
 		struct task_struct *task;
 		int count = 0;
-		seq_printf(seq, "css_set %p\n", cg);
+		seq_printf(seq, "css_set %pK\n", cg);
 		list_for_each_entry(task, &cg->tasks, cg_list) {
 			if (count++ > MAX_TASKS_SHOWN_PER_CSS) {
 				seq_puts(seq, "  ...\n");
diff --git a/kernel/events/core.c b/kernel/events/core.c
index 3f63ea6..55ae884 100755
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -5169,9 +5169,6 @@ struct swevent_htable {
 
 	/* Recursion avoidance in each contexts */
 	int				recursion[PERF_NR_CONTEXTS];
-
-	/* Keeps track of cpu being initialized/exited */
-	bool				online;
 };
 
 static DEFINE_PER_CPU(struct swevent_htable, swevent_htable);
@@ -5418,14 +5415,8 @@ static int perf_swevent_add(struct perf_event *event, int flags)
 	hwc->state = !(flags & PERF_EF_START);
 
 	head = find_swevent_head(swhash, event);
-	if (!head) {
-		/*
-		 * We can race with cpu hotplug code. Do not
-		 * WARN if the cpu just got unplugged.
-		 */
-		WARN_ON_ONCE(swhash->online);
+	if (WARN_ON_ONCE(!head))
 		return -EINVAL;
-	}
 
 	hlist_add_head_rcu(&event->hlist_entry, head);
 
@@ -5497,7 +5488,6 @@ static int swevent_hlist_get_cpu(struct perf_event *event, int cpu)
 	int err = 0;
 
 	mutex_lock(&swhash->hlist_mutex);
-
 	if (!swevent_hlist_deref(swhash) && cpu_online(cpu)) {
 		struct swevent_hlist *hlist;
 
@@ -7528,7 +7518,6 @@ static void __cpuinit perf_event_init_cpu(int cpu)
 	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);
 
 	mutex_lock(&swhash->hlist_mutex);
-	swhash->online = true;
 	if (swhash->hlist_refcount > 0) {
 		struct swevent_hlist *hlist;
 
@@ -7581,14 +7570,7 @@ static void perf_event_exit_cpu_context(int cpu)
 
 static void perf_event_exit_cpu(int cpu)
 {
-	struct swevent_htable *swhash = &per_cpu(swevent_htable, cpu);
-
 	perf_event_exit_cpu_context(cpu);
-
-	mutex_lock(&swhash->hlist_mutex);
-	swhash->online = false;
-	swevent_hlist_release(swhash);
-	mutex_unlock(&swhash->hlist_mutex);
 }
 #else
 static inline void perf_event_exit_cpu(int cpu) { }
diff --git a/kernel/module.c b/kernel/module.c
index 8ccaec9..398f407 100755
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -153,7 +153,6 @@ typedef enum {
 
 #define HASH_SIZE 20
 #define TIMA_SIGN_LEN 256	/* the rsa signature length of lkm_sec_info */
-#define BOOTMODE_RECOVERY 2	/* bootmode in ATAG_CMDLINE for recovery mode */
 
 uint8_t *tci = NULL;
 uint8_t *drv_tci = NULL;
@@ -162,15 +161,6 @@ uint8_t lkm_sec_info_loaded = 0;
 struct mc_session_handle mchandle;
 struct mc_session_handle drv_mchandle;
 
-unsigned int lkmauth_bootmode;
-static int __init lkmauth_bootmode_setup(char *str)
-{
-	get_option(&str, &lkmauth_bootmode);
-	return 1;
-}
-
-__setup("bootmode=", lkmauth_bootmode_setup);
-
 #endif /* End TIMA_ON_MC20 */
 
 /*
@@ -3140,14 +3130,14 @@ static int elf_header_check(struct load_info *info)
 		return -ENOEXEC;
 
 #ifdef TIMA_LKM_AUTH_ENABLED
-	if (lkmauth_bootmode != BOOTMODE_RECOVERY &&
-	    lkmauth(info->hdr, info->len) != RET_LKMAUTH_SUCCESS) {
+	if (lkmauth(info->hdr, info->len) != RET_LKMAUTH_SUCCESS) {
 		pr_err
 		    ("TIMA: lkmauth--unable to load kernel module; module len is %lu.\n",
 		     info->len);
 		return -ENOEXEC;
 	}
-#endif		
+#endif
+
 return 0;
 }
 
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 86a3dcf..81ef73a 100755
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -1656,6 +1656,20 @@ static struct ctl_table fs_table[] = {
 		.proc_handler	= &pipe_proc_fn,
 		.extra1		= &pipe_min_size,
 	},
+	{
+		.procname	= "pipe-user-pages-hard",
+		.data		= &pipe_user_pages_hard,
+		.maxlen		= sizeof(pipe_user_pages_hard),
+		.mode		= 0644,
+		.proc_handler	= proc_doulongvec_minmax,
+	},
+	{
+		.procname	= "pipe-user-pages-soft",
+		.data		= &pipe_user_pages_soft,
+		.maxlen		= sizeof(pipe_user_pages_soft),
+		.mode		= 0644,
+		.proc_handler	= proc_doulongvec_minmax,
+	},
 	{ }
 };
 
diff --git a/lib/asn1_decoder.c b/lib/asn1_decoder.c
index 11b9b01..a076f36 100755
--- a/lib/asn1_decoder.c
+++ b/lib/asn1_decoder.c
@@ -69,7 +69,7 @@ next_tag:
 
 	/* Extract a tag from the data */
 	tag = data[dp++];
-	if (tag == 0) {
+	if (tag == ASN1_EOC) {
 		/* It appears to be an EOC. */
 		if (data[dp++] != 0)
 			goto invalid_eoc;
@@ -91,10 +91,8 @@ next_tag:
 
 	/* Extract the length */
 	len = data[dp++];
-	if (len <= 0x7f) {
-		dp += len;
-		goto next_tag;
-	}
+	if (len <= 0x7f)
+		goto check_length;
 
 	if (unlikely(len == ASN1_INDEFINITE_LENGTH)) {
 		/* Indefinite length */
@@ -105,14 +103,18 @@ next_tag:
 	}
 
 	n = len - 0x80;
-	if (unlikely(n > sizeof(size_t) - 1))
+	if (unlikely(n > sizeof(len) - 1))
 		goto length_too_long;
 	if (unlikely(n > datalen - dp))
 		goto data_overrun_error;
-	for (len = 0; n > 0; n--) {
+	len = 0;
+	for (; n > 0; n--) {
 		len <<= 8;
 		len |= data[dp++];
 	}
+check_length:
+	if (len > datalen - dp)
+		goto data_overrun_error;
 	dp += len;
 	goto next_tag;
 
diff --git a/mm/memory.c b/mm/memory.c
index 0984f39..abf3cad 100755
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -1462,6 +1462,16 @@ int zap_vma_ptes(struct vm_area_struct *vma, unsigned long address,
 }
 EXPORT_SYMBOL_GPL(zap_vma_ptes);
 
+/*
+ * FOLL_FORCE can write to even unwritable pte's, but only
+ * after we've gone through a COW cycle and they are dirty.
+ */
+static inline bool can_follow_write_pte(pte_t pte, unsigned int flags)
+{
+	return pte_write(pte) ||
+		((flags & FOLL_FORCE) && (flags & FOLL_COW) && pte_dirty(pte));
+}
+
 /**
  * follow_page_mask - look up a page descriptor from a user-virtual address
  * @vma: vm_area_struct mapping @address
@@ -1569,7 +1579,7 @@ split_fallthrough:
 	}
 	if ((flags & FOLL_NUMA) && pte_numa(pte))
 		goto no_page;
-	if ((flags & FOLL_WRITE) && !pte_write(pte))
+	if ((flags & FOLL_WRITE) && !can_follow_write_pte(pte, flags))
 		goto unlock;
 
 	page = vm_normal_page(vma, address, pte);
@@ -1876,7 +1886,7 @@ long __get_user_pages(struct task_struct *tsk, struct mm_struct *mm,
 				 */
 				if ((ret & VM_FAULT_WRITE) &&
 				    !(vma->vm_flags & VM_WRITE))
-					foll_flags &= ~FOLL_WRITE;
+					foll_flags |= FOLL_COW;
 
 				cond_resched();
 			}
diff --git a/mm/migrate.c b/mm/migrate.c
index a88c12f..a61500f 100755
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@ -30,6 +30,7 @@
 #include <linux/mempolicy.h>
 #include <linux/vmalloc.h>
 #include <linux/security.h>
+#include <linux/backing-dev.h>
 #include <linux/memcontrol.h>
 #include <linux/syscalls.h>
 #include <linux/hugetlb.h>
@@ -311,6 +312,8 @@ static int migrate_page_move_mapping(struct address_space *mapping,
 		struct page *newpage, struct page *page,
 		struct buffer_head *head, enum migrate_mode mode)
 {
+	struct zone *oldzone, *newzone;
+	int dirty;
 	int expected_count = 0;
 	void **pslot;
 
@@ -321,6 +324,9 @@ static int migrate_page_move_mapping(struct address_space *mapping,
 		return MIGRATEPAGE_SUCCESS;
 	}
 
+	oldzone = page_zone(page);
+	newzone = page_zone(newpage);
+
 	spin_lock_irq(&mapping->tree_lock);
 
 	pslot = radix_tree_lookup_slot(&mapping->page_tree,
@@ -361,6 +367,13 @@ static int migrate_page_move_mapping(struct address_space *mapping,
 		set_page_private(newpage, page_private(page));
 	}
 
+	/* Move dirty while page refs frozen and newpage not yet exposed */
+	dirty = PageDirty(page);
+	if (dirty) {
+		ClearPageDirty(page);
+		SetPageDirty(newpage);
+	}
+
 	radix_tree_replace_slot(pslot, newpage);
 
 	/*
@@ -370,6 +383,9 @@ static int migrate_page_move_mapping(struct address_space *mapping,
 	 */
 	page_unfreeze_refs(page, expected_count - 1);
 
+	spin_unlock(&mapping->tree_lock);
+	/* Leave irq disabled to prevent preemption while updating stats */
+
 	/*
 	 * If moved to a different zone then also account
 	 * the page for that zone. Other VM counters will be
@@ -380,13 +396,19 @@ static int migrate_page_move_mapping(struct address_space *mapping,
 	 * via NR_FILE_PAGES and NR_ANON_PAGES if they
 	 * are mapped to swap space.
 	 */
-	__dec_zone_page_state(page, NR_FILE_PAGES);
-	__inc_zone_page_state(newpage, NR_FILE_PAGES);
-	if (!PageSwapCache(page) && PageSwapBacked(page)) {
-		__dec_zone_page_state(page, NR_SHMEM);
-		__inc_zone_page_state(newpage, NR_SHMEM);
+	if (newzone != oldzone) {
+		__dec_zone_state(oldzone, NR_FILE_PAGES);
+		__inc_zone_state(newzone, NR_FILE_PAGES);
+		if (PageSwapBacked(page) && !PageSwapCache(page)) {
+			__dec_zone_state(oldzone, NR_SHMEM);
+			__inc_zone_state(newzone, NR_SHMEM);
+		}
+		if (dirty && mapping_cap_account_dirty(mapping)) {
+			__dec_zone_state(oldzone, NR_FILE_DIRTY);
+			__inc_zone_state(newzone, NR_FILE_DIRTY);
+		}
 	}
-	spin_unlock_irq(&mapping->tree_lock);
+	local_irq_enable();
 
 	return MIGRATEPAGE_SUCCESS;
 }
@@ -460,20 +482,9 @@ void migrate_page_copy(struct page *newpage, struct page *page)
 	if (PageMappedToDisk(page))
 		SetPageMappedToDisk(newpage);
 
-	if (PageDirty(page)) {
-		clear_page_dirty_for_io(page);
-		/*
-		 * Want to mark the page and the radix tree as dirty, and
-		 * redo the accounting that clear_page_dirty_for_io undid,
-		 * but we can't use set_page_dirty because that function
-		 * is actually a signal that all of the page has become dirty.
-		 * Whereas only part of our page may be dirty.
-		 */
-		if (PageSwapBacked(page))
-			SetPageDirty(newpage);
-		else
-			__set_page_dirty_nobuffers(newpage);
- 	}
+	/* Move dirty on pages not done by migrate_page_move_mapping() */
+	if (PageDirty(page))
+		SetPageDirty(newpage);
 
 	mlock_migrate_page(newpage, page);
 	ksm_migrate_page(newpage, page);
diff --git a/net/core/neighbour.c b/net/core/neighbour.c
index b49e8ba..1b3a85f 100755
--- a/net/core/neighbour.c
+++ b/net/core/neighbour.c
@@ -700,7 +700,7 @@ void neigh_destroy(struct neighbour *neigh)
 	NEIGH_CACHE_STAT_INC(neigh->tbl, destroys);
 
 	if (!neigh->dead) {
-		pr_warn("Destroying alive neighbour %p\n", neigh);
+		pr_warn("Destroying alive neighbour %pK\n", neigh);
 		dump_stack();
 		return;
 	}
@@ -1314,7 +1314,7 @@ int neigh_resolve_output(struct neighbour *neigh, struct sk_buff *skb)
 out:
 	return rc;
 discard:
-	neigh_dbg(1, "%s: dst=%p neigh=%p\n", __func__, dst, neigh);
+	neigh_dbg(1, "%s: dst=%pK neigh=%pK\n", __func__, dst, neigh);
 out_kfree_skb:
 	rc = -EINVAL;
 	kfree_skb(skb);
diff --git a/net/dccp/ipv6.c b/net/dccp/ipv6.c
index 6cf9f77..86eedba 100755
--- a/net/dccp/ipv6.c
+++ b/net/dccp/ipv6.c
@@ -235,7 +235,9 @@ static int dccp_v6_send_response(struct sock *sk, struct request_sock *req)
 	security_req_classify_flow(req, flowi6_to_flowi(&fl6));
 
 
-	final_p = fl6_update_dst(&fl6, np->opt, &final);
+	rcu_read_lock();
+	final_p = fl6_update_dst(&fl6, rcu_dereference(np->opt), &final);
+	rcu_read_unlock();
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p, false);
 	if (IS_ERR(dst)) {
@@ -252,7 +254,10 @@ static int dccp_v6_send_response(struct sock *sk, struct request_sock *req)
 							 &ireq6->loc_addr,
 							 &ireq6->rmt_addr);
 		fl6.daddr = ireq6->rmt_addr;
-		err = ip6_xmit(sk, skb, &fl6, np->opt, np->tclass);
+		rcu_read_lock();
+		err = ip6_xmit(sk, skb, &fl6, rcu_dereference(np->opt),
+			       np->tclass);
+		rcu_read_unlock();
 		err = net_xmit_eval(err);
 	}
 
@@ -448,6 +453,7 @@ static struct sock *dccp_v6_request_recv_sock(struct sock *sk,
 {
 	struct inet6_request_sock *ireq6 = inet6_rsk(req);
 	struct ipv6_pinfo *newnp, *np = inet6_sk(sk);
+	struct ipv6_txoptions *opt;
 	struct inet_sock *newinet;
 	struct dccp6_sock *newdp6;
 	struct sock *newsk;
@@ -571,13 +577,15 @@ static struct sock *dccp_v6_request_recv_sock(struct sock *sk,
 	 * Yes, keeping reference count would be much more clever, but we make
 	 * one more one thing there: reattach optmem to newsk.
 	 */
-	if (np->opt != NULL)
-		newnp->opt = ipv6_dup_options(newsk, np->opt);
-
+	opt = rcu_dereference(np->opt);
+	if (opt) {
+		opt = ipv6_dup_options(newsk, opt);
+		RCU_INIT_POINTER(newnp->opt, opt);
+	}
 	inet_csk(newsk)->icsk_ext_hdr_len = 0;
-	if (newnp->opt != NULL)
-		inet_csk(newsk)->icsk_ext_hdr_len = (newnp->opt->opt_nflen +
-						     newnp->opt->opt_flen);
+	if (opt)
+		inet_csk(newsk)->icsk_ext_hdr_len = opt->opt_nflen +
+						    opt->opt_flen;
 
 	dccp_sync_mss(newsk, dst_mtu(dst));
 
@@ -829,6 +837,7 @@ static int dccp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct dccp_sock *dp = dccp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
+	struct ipv6_txoptions *opt;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
 	int addr_type;
@@ -931,7 +940,8 @@ static int dccp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 	fl6.fl6_sport = inet->inet_sport;
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
-	final_p = fl6_update_dst(&fl6, np->opt, &final);
+	opt = rcu_dereference_protected(np->opt, sock_owned_by_user(sk));
+	final_p = fl6_update_dst(&fl6, opt, &final);
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p, true);
 	if (IS_ERR(dst)) {
@@ -951,9 +961,8 @@ static int dccp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 	__ip6_dst_store(sk, dst, NULL, NULL);
 
 	icsk->icsk_ext_hdr_len = 0;
-	if (np->opt != NULL)
-		icsk->icsk_ext_hdr_len = (np->opt->opt_flen +
-					  np->opt->opt_nflen);
+	if (opt)
+		icsk->icsk_ext_hdr_len = opt->opt_flen + opt->opt_nflen;
 
 	inet->inet_dport = usin->sin6_port;
 
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index ef2b137..6cbfec2 100755
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -68,6 +68,7 @@
 #include <linux/module.h>
 #include <linux/sysctl.h>
 #include <linux/kernel.h>
+#include <linux/reciprocal_div.h>
 #include <net/dst.h>
 #include <net/tcp.h>
 #include <net/inet_common.h>
@@ -92,7 +93,7 @@ int sysctl_tcp_adv_win_scale __read_mostly = 1;
 EXPORT_SYMBOL(sysctl_tcp_adv_win_scale);
 
 /* rfc5961 challenge ack rate limiting */
-int sysctl_tcp_challenge_ack_limit = 100;
+int sysctl_tcp_challenge_ack_limit = 1000;
 
 int sysctl_tcp_stdurg __read_mostly;
 int sysctl_tcp_rfc1337 __read_mostly;
@@ -3404,12 +3405,19 @@ static void tcp_send_challenge_ack(struct sock *sk)
 	static u32 challenge_timestamp;
 	static unsigned int challenge_count;
 	u32 now = jiffies / HZ;
+	u32 count;
 
 	if (now != challenge_timestamp) {
+		u32 half = (sysctl_tcp_challenge_ack_limit + 1) >> 1;
+
 		challenge_timestamp = now;
-		challenge_count = 0;
+		ACCESS_ONCE(challenge_count) = half +
+				  reciprocal_divide(prandom_u32(),
+					sysctl_tcp_challenge_ack_limit);
 	}
-	if (++challenge_count <= sysctl_tcp_challenge_ack_limit) {
+	count = ACCESS_ONCE(challenge_count);
+	if (count > 0) {
+		ACCESS_ONCE(challenge_count) = count - 1;
 		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPCHALLENGEACK);
 		tcp_send_ack(sk);
 	}
diff --git a/net/ipv6/af_inet6.c b/net/ipv6/af_inet6.c
index d4f13db..ab130af 100755
--- a/net/ipv6/af_inet6.c
+++ b/net/ipv6/af_inet6.c
@@ -453,9 +453,11 @@ void inet6_destroy_sock(struct sock *sk)
 
 	/* Free tx options */
 
-	opt = xchg(&np->opt, NULL);
-	if (opt != NULL)
-		sock_kfree_s(sk, opt, opt->tot_len);
+	opt = xchg((__force struct ipv6_txoptions **)&np->opt, NULL);
+	if (opt) {
+		atomic_sub(opt->tot_len, &sk->sk_omem_alloc);
+		txopt_put(opt);
+	}
 }
 EXPORT_SYMBOL_GPL(inet6_destroy_sock);
 
@@ -702,7 +704,10 @@ int inet6_sk_rebuild_header(struct sock *sk)
 		fl6.flowi6_uid = sock_i_uid(sk);
 		security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
-		final_p = fl6_update_dst(&fl6, np->opt, &final);
+		rcu_read_lock();
+		final_p = fl6_update_dst(&fl6, rcu_dereference(np->opt),
+					 &final);
+		rcu_read_unlock();
 
 		dst = ip6_dst_lookup_flow(sk, &fl6, final_p, false);
 		if (IS_ERR(dst)) {
diff --git a/net/ipv6/datagram.c b/net/ipv6/datagram.c
index e9a8ca6..58e6cf7 100755
--- a/net/ipv6/datagram.c
+++ b/net/ipv6/datagram.c
@@ -169,8 +169,10 @@ ipv4_connected:
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
-	opt = flowlabel ? flowlabel->opt : np->opt;
+	rcu_read_lock();
+	opt = flowlabel ? flowlabel->opt : rcu_dereference(np->opt);
 	final_p = fl6_update_dst(&fl6, opt, &final);
+	rcu_read_unlock();
 
 	dst = ip6_dst_lookup_flow(sk, &fl6, final_p, true);
 	err = 0;
diff --git a/net/ipv6/exthdrs.c b/net/ipv6/exthdrs.c
index 8d67900..33dbd6c 100755
--- a/net/ipv6/exthdrs.c
+++ b/net/ipv6/exthdrs.c
@@ -727,6 +727,7 @@ ipv6_dup_options(struct sock *sk, struct ipv6_txoptions *opt)
 			*((char **)&opt2->dst1opt) += dif;
 		if (opt2->srcrt)
 			*((char **)&opt2->srcrt) += dif;
+		atomic_set(&opt2->refcnt, 1);
 	}
 	return opt2;
 }
@@ -790,7 +791,7 @@ ipv6_renew_options(struct sock *sk, struct ipv6_txoptions *opt,
 		return ERR_PTR(-ENOBUFS);
 
 	memset(opt2, 0, tot_len);
-
+	atomic_set(&opt2->refcnt, 1);
 	opt2->tot_len = tot_len;
 	p = (char *)(opt2 + 1);
 
diff --git a/net/ipv6/inet6_connection_sock.c b/net/ipv6/inet6_connection_sock.c
index 74b98ad..698ec12 100755
--- a/net/ipv6/inet6_connection_sock.c
+++ b/net/ipv6/inet6_connection_sock.c
@@ -78,7 +78,9 @@ struct dst_entry *inet6_csk_route_req(struct sock *sk,
 	memset(fl6, 0, sizeof(*fl6));
 	fl6->flowi6_proto = IPPROTO_TCP;
 	fl6->daddr = treq->rmt_addr;
-	final_p = fl6_update_dst(fl6, np->opt, &final);
+	rcu_read_lock();
+	final_p = fl6_update_dst(fl6, rcu_dereference(np->opt), &final);
+	rcu_read_unlock();
 	fl6->saddr = treq->loc_addr;
 	fl6->flowi6_oif = treq->iif;
 	fl6->flowi6_mark = inet_rsk(req)->ir_mark;
@@ -218,7 +220,9 @@ static struct dst_entry *inet6_csk_route_socket(struct sock *sk,
 	fl6->flowi6_uid = sock_i_uid(sk);
 	security_sk_classify_flow(sk, flowi6_to_flowi(fl6));
 
-	final_p = fl6_update_dst(fl6, np->opt, &final);
+	rcu_read_lock();
+	final_p = fl6_update_dst(fl6, rcu_dereference(np->opt), &final);
+	rcu_read_unlock();
 
 	dst = __inet6_csk_dst_check(sk, np->dst_cookie);
 	if (!dst) {
@@ -252,7 +256,8 @@ int inet6_csk_xmit(struct sk_buff *skb, struct flowi *fl_unused)
 	/* Restore final destination back after routing done */
 	fl6.daddr = np->daddr;
 
-	res = ip6_xmit(sk, skb, &fl6, np->opt, np->tclass);
+	res = ip6_xmit(sk, skb, &fl6, rcu_dereference(np->opt),
+		       np->tclass);
 	rcu_read_unlock();
 	return res;
 }
diff --git a/net/ipv6/ipv6_sockglue.c b/net/ipv6/ipv6_sockglue.c
index 1a3d3c6..b1667a7 100755
--- a/net/ipv6/ipv6_sockglue.c
+++ b/net/ipv6/ipv6_sockglue.c
@@ -114,10 +114,12 @@ struct ipv6_txoptions *ipv6_update_options(struct sock *sk,
 			icsk->icsk_ext_hdr_len = opt->opt_flen + opt->opt_nflen;
 			icsk->icsk_sync_mss(sk, icsk->icsk_pmtu_cookie);
 		}
-		opt = xchg(&inet6_sk(sk)->opt, opt);
+		opt = xchg((__force struct ipv6_txoptions **)&inet6_sk(sk)->opt,
+			   opt);
 	} else {
 		spin_lock(&sk->sk_dst_lock);
-		opt = xchg(&inet6_sk(sk)->opt, opt);
+		opt = xchg((__force struct ipv6_txoptions **)&inet6_sk(sk)->opt,
+			   opt);
 		spin_unlock(&sk->sk_dst_lock);
 	}
 	sk_dst_reset(sk);
@@ -222,9 +224,12 @@ static int do_ipv6_setsockopt(struct sock *sk, int level, int optname,
 				sk->sk_socket->ops = &inet_dgram_ops;
 				sk->sk_family = PF_INET;
 			}
-			opt = xchg(&np->opt, NULL);
-			if (opt)
-				sock_kfree_s(sk, opt, opt->tot_len);
+			opt = xchg((__force struct ipv6_txoptions **)&np->opt,
+				   NULL);
+			if (opt) {
+				atomic_sub(opt->tot_len, &sk->sk_omem_alloc);
+				txopt_put(opt);
+			}
 			pktopt = xchg(&np->pktoptions, NULL);
 			kfree_skb(pktopt);
 
@@ -394,7 +399,8 @@ static int do_ipv6_setsockopt(struct sock *sk, int level, int optname,
 		if (optname != IPV6_RTHDR && !ns_capable(net->user_ns, CAP_NET_RAW))
 			break;
 
-		opt = ipv6_renew_options(sk, np->opt, optname,
+		opt = rcu_dereference_protected(np->opt, sock_owned_by_user(sk));
+		opt = ipv6_renew_options(sk, opt, optname,
 					 (struct ipv6_opt_hdr __user *)optval,
 					 optlen);
 		if (IS_ERR(opt)) {
@@ -423,8 +429,10 @@ static int do_ipv6_setsockopt(struct sock *sk, int level, int optname,
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 sticky_done:
-		if (opt)
-			sock_kfree_s(sk, opt, opt->tot_len);
+		if (opt) {
+			atomic_sub(opt->tot_len, &sk->sk_omem_alloc);
+			txopt_put(opt);
+		}
 		break;
 	}
 
@@ -477,6 +485,7 @@ sticky_done:
 			break;
 
 		memset(opt, 0, sizeof(*opt));
+		atomic_set(&opt->refcnt, 1);
 		opt->tot_len = sizeof(*opt) + optlen;
 		retv = -EFAULT;
 		if (copy_from_user(opt+1, optval, optlen))
@@ -493,8 +502,10 @@ update:
 		retv = 0;
 		opt = ipv6_update_options(sk, opt);
 done:
-		if (opt)
-			sock_kfree_s(sk, opt, opt->tot_len);
+		if (opt) {
+			atomic_sub(opt->tot_len, &sk->sk_omem_alloc);
+			txopt_put(opt);
+		}
 		break;
 	}
 	case IPV6_UNICAST_HOPS:
@@ -1094,10 +1105,11 @@ static int do_ipv6_getsockopt(struct sock *sk, int level, int optname,
 	case IPV6_RTHDR:
 	case IPV6_DSTOPTS:
 	{
+		struct ipv6_txoptions *opt;
 
 		lock_sock(sk);
-		len = ipv6_getsockopt_sticky(sk, np->opt,
-					     optname, optval, len);
+		opt = rcu_dereference_protected(np->opt, sock_owned_by_user(sk));
+		len = ipv6_getsockopt_sticky(sk, opt, optname, optval, len);
 		release_sock(sk);
 		/* check if ipv6_getsockopt_sticky() returns err code */
 		if (len < 0)
diff --git a/net/ipv6/raw.c b/net/ipv6/raw.c
index 32c0d4e..6bfe997 100755
--- a/net/ipv6/raw.c
+++ b/net/ipv6/raw.c
@@ -726,6 +726,7 @@ static int rawv6_probe_proto_opt(struct flowi6 *fl6, struct msghdr *msg)
 static int rawv6_sendmsg(struct kiocb *iocb, struct sock *sk,
 		   struct msghdr *msg, size_t len)
 {
+	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ipv6_txoptions opt_space;
 	struct sockaddr_in6 * sin6 = (struct sockaddr_in6 *) msg->msg_name;
 	struct in6_addr *daddr, *final_p, final;
@@ -833,8 +834,10 @@ static int rawv6_sendmsg(struct kiocb *iocb, struct sock *sk,
 		if (!(opt->opt_nflen|opt->opt_flen))
 			opt = NULL;
 	}
-	if (opt == NULL)
-		opt = np->opt;
+	if (!opt) {
+		opt = txopt_get(np);
+		opt_to_free = opt;
+	}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
@@ -901,6 +904,7 @@ done:
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
+	txopt_put(opt_to_free);
 	return err<0?err:len;
 do_confirm:
 	dst_confirm(dst);
diff --git a/net/ipv6/syncookies.c b/net/ipv6/syncookies.c
index 267bf69..20cdac7 100755
--- a/net/ipv6/syncookies.c
+++ b/net/ipv6/syncookies.c
@@ -241,7 +241,7 @@ struct sock *cookie_v6_check(struct sock *sk, struct sk_buff *skb)
 		memset(&fl6, 0, sizeof(fl6));
 		fl6.flowi6_proto = IPPROTO_TCP;
 		fl6.daddr = ireq6->rmt_addr;
-		final_p = fl6_update_dst(&fl6, np->opt, &final);
+		final_p = fl6_update_dst(&fl6, rcu_dereference(np->opt), &final);
 		fl6.saddr = ireq6->loc_addr;
 		fl6.flowi6_oif = sk->sk_bound_dev_if;
 		fl6.flowi6_mark = ireq->ir_mark;
diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c
index 737501c..a22968c 100755
--- a/net/ipv6/tcp_ipv6.c
+++ b/net/ipv6/tcp_ipv6.c
@@ -155,6 +155,7 @@ int tcp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 	struct ipv6_pinfo *np = inet6_sk(sk);
 	struct tcp_sock *tp = tcp_sk(sk);
 	struct in6_addr *saddr = NULL, *final_p, final;
+	struct ipv6_txoptions *opt;
 	struct rt6_info *rt;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
@@ -286,7 +287,8 @@ int tcp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 	fl6.fl6_sport = inet->inet_sport;
 	fl6.flowi6_uid = sock_i_uid(sk);
 
-	final_p = fl6_update_dst(&fl6, np->opt, &final);
+	opt = rcu_dereference_protected(np->opt, sock_owned_by_user(sk));
+	final_p = fl6_update_dst(&fl6, opt, &final);
 
 	security_sk_classify_flow(sk, flowi6_to_flowi(&fl6));
 
@@ -315,9 +317,9 @@ int tcp_v6_connect(struct sock *sk, struct sockaddr *uaddr,
 		tcp_fetch_timewait_stamp(sk, dst);
 
 	icsk->icsk_ext_hdr_len = 0;
-	if (np->opt)
-		icsk->icsk_ext_hdr_len = (np->opt->opt_flen +
-					  np->opt->opt_nflen);
+	if (opt)
+		icsk->icsk_ext_hdr_len = opt->opt_flen +
+					 opt->opt_nflen;
 
 	tp->rx_opt.mss_clamp = IPV6_MIN_MTU - sizeof(struct tcphdr) - sizeof(struct ipv6hdr);
 
@@ -591,7 +593,8 @@ static int tcp_v6_send_synack(struct sock *sk, struct dst_entry *dst,
 
 		fl6->daddr = treq->rmt_addr;
 		skb_set_queue_mapping(skb, queue_mapping);
-		err = ip6_xmit(sk, skb, fl6, np->opt, np->tclass);
+		err = ip6_xmit(sk, skb, fl6, rcu_dereference(np->opt),
+			       np->tclass);
 		err = net_xmit_eval(err);
 #ifdef CONFIG_MPTCP
 		if (!tcp_rsk(req)->snt_synack && !err)
@@ -1384,6 +1387,7 @@ struct sock * tcp_v6_syn_recv_sock(struct sock *sk, struct sk_buff *skb,
 	struct inet6_request_sock *treq;
 	struct ipv6_pinfo *newnp, *np = inet6_sk(sk);
 	struct tcp6_sock *newtcp6sk;
+	struct ipv6_txoptions *opt;
 	struct inet_sock *newinet;
 	struct tcp_sock *newtp;
 	struct sock *newsk;
@@ -1522,13 +1526,15 @@ struct sock * tcp_v6_syn_recv_sock(struct sock *sk, struct sk_buff *skb,
 	   but we make one more one thing there: reattach optmem
 	   to newsk.
 	 */
-	if (np->opt)
-		newnp->opt = ipv6_dup_options(newsk, np->opt);
-
+	opt = rcu_dereference(np->opt);
+	if (opt) {
+		opt = ipv6_dup_options(newsk, opt);
+		RCU_INIT_POINTER(newnp->opt, opt);
+	}
 	inet_csk(newsk)->icsk_ext_hdr_len = 0;
-	if (newnp->opt)
-		inet_csk(newsk)->icsk_ext_hdr_len = (newnp->opt->opt_nflen +
-						     newnp->opt->opt_flen);
+	if (opt)
+		inet_csk(newsk)->icsk_ext_hdr_len = opt->opt_nflen +
+						    opt->opt_flen;
 
 	tcp_mtup_init(newsk);
 	tcp_sync_mss(newsk, dst_mtu(dst));
diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c
index a963e61..19beeca 100755
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@ -1016,6 +1016,7 @@ int udpv6_sendmsg(struct kiocb *iocb, struct sock *sk,
 	struct sockaddr_in6 *sin6 = (struct sockaddr_in6 *) msg->msg_name;
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_txoptions *opt = NULL;
+	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct flowi6 fl6;
 	struct dst_entry *dst;
@@ -1170,8 +1171,10 @@ do_udp_sendmsg:
 			opt = NULL;
 		connected = 0;
 	}
-	if (opt == NULL)
-		opt = np->opt;
+	if (!opt) {
+		opt = txopt_get(np);
+		opt_to_free = opt;
+	}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
@@ -1272,6 +1275,7 @@ do_append_data:
 out:
 	dst_release(dst);
 	fl6_sock_release(flowlabel);
+	txopt_put(opt_to_free);
 	if (!err)
 		return len;
 	/*
diff --git a/net/l2tp/l2tp_ip6.c b/net/l2tp/l2tp_ip6.c
index e6e8408..3b61ddd 100755
--- a/net/l2tp/l2tp_ip6.c
+++ b/net/l2tp/l2tp_ip6.c
@@ -485,6 +485,7 @@ static int l2tp_ip6_sendmsg(struct kiocb *iocb, struct sock *sk,
 		(struct sockaddr_l2tpip6 *) msg->msg_name;
 	struct in6_addr *daddr, *final_p, final;
 	struct ipv6_pinfo *np = inet6_sk(sk);
+	struct ipv6_txoptions *opt_to_free = NULL;
 	struct ipv6_txoptions *opt = NULL;
 	struct ip6_flowlabel *flowlabel = NULL;
 	struct dst_entry *dst = NULL;
@@ -575,8 +576,10 @@ static int l2tp_ip6_sendmsg(struct kiocb *iocb, struct sock *sk,
 			opt = NULL;
 	}
 
-	if (opt == NULL)
-		opt = np->opt;
+	if (!opt) {
+		opt = txopt_get(np);
+		opt_to_free = opt;
+	}
 	if (flowlabel)
 		opt = fl6_merge_options(&opt_space, flowlabel, opt);
 	opt = ipv6_fixup_options(&opt_space, opt);
@@ -637,6 +640,7 @@ done:
 	dst_release(dst);
 out:
 	fl6_sock_release(flowlabel);
+	txopt_put(opt_to_free);
 
 	return err < 0 ? err : len;
 
diff --git a/net/netfilter/xt_qtaguid.c b/net/netfilter/xt_qtaguid.c
index 24c1f30..eb65f53 100755
--- a/net/netfilter/xt_qtaguid.c
+++ b/net/netfilter/xt_qtaguid.c
@@ -2518,7 +2518,7 @@ static int pp_stats_line(struct seq_file *m, struct tag_stat *ts_entry,
 	uid_t stat_uid = get_uid_from_tag(tag);
 	struct proc_print_info *ppi = m->private;
 	/* Detailed tags are not available to everybody */
-	if (get_atag_from_tag(tag) && !can_read_other_uid_stats(stat_uid)) {
+	if (!can_read_other_uid_stats(stat_uid)) {
 		CT_DEBUG("qtaguid: stats line: "
 			 "%s 0x%llx %u: insufficient priv "
 			 "from pid=%u tgid=%u uid=%u stats.gid=%u\n",
diff --git a/net/socket.c b/net/socket.c
index 2fefb31..9d188ae 100755
--- a/net/socket.c
+++ b/net/socket.c
@@ -2389,31 +2389,31 @@ int __sys_recvmmsg(int fd, struct mmsghdr __user *mmsg, unsigned int vlen,
 			break;
 	}
 
-out_put:
-	fput_light(sock->file, fput_needed);
-
 	if (err == 0)
-		return datagrams;
+		goto out_put;
 
-	if (datagrams != 0) {
+	if (datagrams == 0) {
+		datagrams = err;
+		goto out_put;
+	}
+
+	/*
+	 * We may return less entries than requested (vlen) if the
+	 * sock is non block and there aren't enough datagrams...
+	 */
+	if (err != -EAGAIN) {
 		/*
-		 * We may return less entries than requested (vlen) if the
-		 * sock is non block and there aren't enough datagrams...
+		 * ... or  if recvmsg returns an error after we
+		 * received some datagrams, where we record the
+		 * error to return on the next call or if the
+		 * app asks about it using getsockopt(SO_ERROR).
 		 */
-		if (err != -EAGAIN) {
-			/*
-			 * ... or  if recvmsg returns an error after we
-			 * received some datagrams, where we record the
-			 * error to return on the next call or if the
-			 * app asks about it using getsockopt(SO_ERROR).
-			 */
-			sock->sk->sk_err = -err;
-		}
-
-		return datagrams;
+		sock->sk->sk_err = -err;
 	}
+out_put:
+	fput_light(sock->file, fput_needed);
 
-	return err;
+	return datagrams;
 }
 
 SYSCALL_DEFINE5(recvmmsg, int, fd, struct mmsghdr __user *, mmsg,
diff --git a/net/unix/af_unix.c b/net/unix/af_unix.c
index 538d7fc..b137d22 100755
--- a/net/unix/af_unix.c
+++ b/net/unix/af_unix.c
@@ -314,6 +314,118 @@ found:
 	return s;
 }
 
+/* Support code for asymmetrically connected dgram sockets
+ *
+ * If a datagram socket is connected to a socket not itself connected
+ * to the first socket (eg, /dev/log), clients may only enqueue more
+ * messages if the present receive queue of the server socket is not
+ * "too large". This means there's a second writeability condition
+ * poll and sendmsg need to test. The dgram recv code will do a wake
+ * up on the peer_wait wait queue of a socket upon reception of a
+ * datagram which needs to be propagated to sleeping would-be writers
+ * since these might not have sent anything so far. This can't be
+ * accomplished via poll_wait because the lifetime of the server
+ * socket might be less than that of its clients if these break their
+ * association with it or if the server socket is closed while clients
+ * are still connected to it and there's no way to inform "a polling
+ * implementation" that it should let go of a certain wait queue
+ *
+ * In order to propagate a wake up, a wait_queue_t of the client
+ * socket is enqueued on the peer_wait queue of the server socket
+ * whose wake function does a wake_up on the ordinary client socket
+ * wait queue. This connection is established whenever a write (or
+ * poll for write) hit the flow control condition and broken when the
+ * association to the server socket is dissolved or after a wake up
+ * was relayed.
+ */
+
+static int unix_dgram_peer_wake_relay(wait_queue_t *q, unsigned mode, int flags,
+				      void *key)
+{
+	struct unix_sock *u;
+	wait_queue_head_t *u_sleep;
+
+	u = container_of(q, struct unix_sock, peer_wake);
+
+	__remove_wait_queue(&unix_sk(u->peer_wake.private)->peer_wait,
+			    q);
+	u->peer_wake.private = NULL;
+
+	/* relaying can only happen while the wq still exists */
+	u_sleep = sk_sleep(&u->sk);
+	if (u_sleep)
+		wake_up_interruptible_poll(u_sleep, key);
+
+	return 0;
+}
+
+static int unix_dgram_peer_wake_connect(struct sock *sk, struct sock *other)
+{
+	struct unix_sock *u, *u_other;
+	int rc;
+
+	u = unix_sk(sk);
+	u_other = unix_sk(other);
+	rc = 0;
+	spin_lock(&u_other->peer_wait.lock);
+
+	if (!u->peer_wake.private) {
+		u->peer_wake.private = other;
+		__add_wait_queue(&u_other->peer_wait, &u->peer_wake);
+
+		rc = 1;
+	}
+
+	spin_unlock(&u_other->peer_wait.lock);
+	return rc;
+}
+
+static void unix_dgram_peer_wake_disconnect(struct sock *sk,
+					    struct sock *other)
+{
+	struct unix_sock *u, *u_other;
+
+	u = unix_sk(sk);
+	u_other = unix_sk(other);
+	spin_lock(&u_other->peer_wait.lock);
+
+	if (u->peer_wake.private == other) {
+		__remove_wait_queue(&u_other->peer_wait, &u->peer_wake);
+		u->peer_wake.private = NULL;
+	}
+
+	spin_unlock(&u_other->peer_wait.lock);
+}
+
+static void unix_dgram_peer_wake_disconnect_wakeup(struct sock *sk,
+						   struct sock *other)
+{
+	unix_dgram_peer_wake_disconnect(sk, other);
+	wake_up_interruptible_poll(sk_sleep(sk),
+				   POLLOUT |
+				   POLLWRNORM |
+				   POLLWRBAND);
+}
+
+/* preconditions:
+ *	- unix_peer(sk) == other
+ *	- association is stable
+ */
+static int unix_dgram_peer_wake_me(struct sock *sk, struct sock *other)
+{
+	int connected;
+
+	connected = unix_dgram_peer_wake_connect(sk, other);
+
+	if (unix_recvq_full(other))
+		return 1;
+
+	if (connected)
+		unix_dgram_peer_wake_disconnect(sk, other);
+
+	return 0;
+}
+
 static inline int unix_writable(struct sock *sk)
 {
 	return (atomic_read(&sk->sk_wmem_alloc) << 2) <= sk->sk_sndbuf;
@@ -418,6 +530,8 @@ static void unix_release_sock(struct sock *sk, int embrion)
 			skpair->sk_state_change(skpair);
 			sk_wake_async(skpair, SOCK_WAKE_WAITD, POLL_HUP);
 		}
+
+		unix_dgram_peer_wake_disconnect(sk, skpair);
 		sock_put(skpair); /* It may now die */
 		unix_peer(sk) = NULL;
 	}
@@ -651,6 +765,7 @@ static struct sock *unix_create1(struct net *net, struct socket *sock)
 	INIT_LIST_HEAD(&u->link);
 	mutex_init(&u->readlock); /* single task reading lock */
 	init_waitqueue_head(&u->peer_wait);
+	init_waitqueue_func_entry(&u->peer_wake, unix_dgram_peer_wake_relay);
 	unix_insert_socket(unix_sockets_unbound(sk), sk);
 out:
 	if (sk == NULL)
@@ -1018,6 +1133,8 @@ restart:
 	if (unix_peer(sk)) {
 		struct sock *old_peer = unix_peer(sk);
 		unix_peer(sk) = other;
+		unix_dgram_peer_wake_disconnect_wakeup(sk, old_peer);
+
 		unix_state_double_unlock(sk, other);
 
 		if (other != old_peer)
@@ -1473,6 +1590,7 @@ static int unix_dgram_sendmsg(struct kiocb *kiocb, struct socket *sock,
 	struct scm_cookie tmp_scm;
 	int max_level;
 	int data_len = 0;
+	int sk_locked;
 
 	if (NULL == siocb->scm)
 		siocb->scm = &tmp_scm;
@@ -1549,12 +1667,14 @@ restart:
 		goto out_free;
 	}
 
+	sk_locked = 0;
 	unix_state_lock(other);
+restart_locked:
 	err = -EPERM;
 	if (!unix_may_send(sk, other))
 		goto out_unlock;
 
-	if (sock_flag(other, SOCK_DEAD)) {
+	if (unlikely(sock_flag(other, SOCK_DEAD))) {
 		/*
 		 *	Check with 1003.1g - what should
 		 *	datagram error
@@ -1562,10 +1682,14 @@ restart:
 		unix_state_unlock(other);
 		sock_put(other);
 
+		if (!sk_locked)
+			unix_state_lock(sk);
+
 		err = 0;
-		unix_state_lock(sk);
 		if (unix_peer(sk) == other) {
 			unix_peer(sk) = NULL;
+			unix_dgram_peer_wake_disconnect_wakeup(sk, other);
+
 			unix_state_unlock(sk);
 
 			unix_dgram_disconnected(sk, other);
@@ -1591,21 +1715,38 @@ restart:
 			goto out_unlock;
 	}
 
-	if (unix_peer(other) != sk && unix_recvq_full(other)) {
-		if (!timeo) {
-			err = -EAGAIN;
-			goto out_unlock;
+	if (unlikely(unix_peer(other) != sk && unix_recvq_full(other))) {
+		if (timeo) {
+			timeo = unix_wait_for_peer(other, timeo);
+
+			err = sock_intr_errno(timeo);
+			if (signal_pending(current))
+				goto out_free;
+
+			goto restart;
 		}
 
-		timeo = unix_wait_for_peer(other, timeo);
+		if (!sk_locked) {
+			unix_state_unlock(other);
+			unix_state_double_lock(sk, other);
+		}
 
-		err = sock_intr_errno(timeo);
-		if (signal_pending(current))
-			goto out_free;
+		if (unix_peer(sk) != other ||
+		    unix_dgram_peer_wake_me(sk, other)) {
+			err = -EAGAIN;
+			sk_locked = 1;
+			goto out_unlock;
+		}
 
-		goto restart;
+		if (!sk_locked) {
+			sk_locked = 1;
+			goto restart_locked;
+		}
 	}
 
+	if (unlikely(sk_locked))
+		unix_state_unlock(sk);
+
 	if (sock_flag(other, SOCK_RCVTSTAMP))
 		__net_timestamp(skb);
 	maybe_add_creds(skb, sock, other);
@@ -1619,6 +1760,8 @@ restart:
 	return len;
 
 out_unlock:
+	if (sk_locked)
+		unix_state_unlock(sk);
 	unix_state_unlock(other);
 out_free:
 	kfree_skb(skb);
@@ -2254,14 +2397,16 @@ static unsigned int unix_dgram_poll(struct file *file, struct socket *sock,
 		return mask;
 
 	writable = unix_writable(sk);
-	other = unix_peer_get(sk);
-	if (other) {
-		if (unix_peer(other) != sk) {
-			sock_poll_wait(file, &unix_sk(other)->peer_wait, wait);
-			if (unix_recvq_full(other))
-				writable = 0;
-		}
-		sock_put(other);
+	if (writable) {
+		unix_state_lock(sk);
+
+		other = unix_peer(sk);
+		if (other && unix_peer(other) != sk &&
+		    unix_recvq_full(other) &&
+		    unix_dgram_peer_wake_me(sk, other))
+			writable = 0;
+
+		unix_state_unlock(sk);
 	}
 
 	if (writable)
diff --git a/security/keys/key.c b/security/keys/key.c
index 8fb7c7b..6595b2d 100755
--- a/security/keys/key.c
+++ b/security/keys/key.c
@@ -580,7 +580,7 @@ int key_reject_and_link(struct key *key,
 
 	mutex_unlock(&key_construction_mutex);
 
-	if (keyring)
+	if (keyring && link_ret == 0)
 		__key_link_end(keyring, key->type, prealloc);
 
 	/* wake up anyone waiting for a key to be constructed */
